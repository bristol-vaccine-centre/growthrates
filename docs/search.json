[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 growthrates authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/covid-timeseries.html","id":"incidence-and-growth-rate-from-case-positive-counts","dir":"Articles","previous_headings":"","what":"Incidence and growth rate from case positive counts","title":"England COVID-19 cases","text":"method uses case positive count dataset bundled growth rates age stratified (age grouping class column). look age stratification different vignettes instance want aggregate England wide rate. purpose time_aggregate() performs simple summarisation. raw covid case count log1p scale total detected cases per day.  Major events timeseries can plotted axes. ’ve focussed first 2 years pandemic:  incidence model assumes case rates result Poisson process rate estimated time varying locally fitted polynomial degree defined deg parameter, using log link function, according methods Loader et al. (see utils::citation(\"locfit\")). fitting process local maximum likelihood estimation uses bandwidth defined account data points within window time point estimated. gradient fitted polynomial log scale, exponential growth rate. scale independent view rate growth epidemic. estimation methodology compared consensus estimates SPI-M-O UK government advisory group red, shifted forward time 21 days. SPI-M-O estimates made pandemic retrospective whereas ones can use information time point now may better represent timing changes.  state epidemic described incidence growth, phase plots allow us see different time points. case epidemic state 10 weeks leading Christmas 2021, 2022 2023:","code":"england_covid %>% dplyr::glimpse() ## Rows: 26,790 ## Columns: 5 ## Groups: class [19] ## $ date  <date> 2023-12-09, 2023-12-09, 2023-12-09, 2023-12-09, 2023-12-09, 202… ## $ class <fct> 00_04, 05_09, 10_14, 15_19, 20_24, 25_29, 30_34, 35_39, 40_44, 4… ## $ count <dbl> 24, 8, 8, 4, 21, 20, 29, 36, 41, 59, 53, 54, 56, 54, 67, 72, 56,… ## $ denom <dbl> 771, 771, 771, 771, 771, 771, 771, 771, 771, 771, 771, 771, 771,… ## $ time  <time_prd> 1409, 1409, 1409, 1409, 1409, 1409, 1409, 1409, 1409, 1409,… tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count)) fit = tmp %>%    poisson_locfit_model()   plot_incidence(fit,raw = tmp, colour=\"blue\",size=0.025)+   scale_y_log1p(n=7) plot_incidence(fit, raw = tmp,events = england_events, colour=\"blue\",size=0.025)+   scale_y_log1p(n=7) + ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\"))) plot_growth_rate(fit,events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=england_consensus_growth_rate,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. plot_growth_phase(fit,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7,     colour=\"blue\" )"},{"path":"/articles/covid-timeseries.html","id":"reproduction-number-estimation-from-growth-rates","dir":"Articles","previous_headings":"","what":"Reproduction number estimation from growth rates","title":"England COVID-19 cases","text":"growth rate unit “per day” example. can derive reproduction number. Using methods Wallinga Lipsitch estimate infectivity profile COVID-19. describes probability infectee infected x days infector, includes temporal dimension rendering reproduction number dimensionless quantity reflecting average number infectees resulting infector. growthrates estimate infectivity profile based meta-analysis serial interval estimates COVID-19. infectivity profile bootstrapped set discrete probability distributions. truncated 14 days.  growth rate estimate methods uses 1000 bootstraps propagate uncertainty hence somewhat slow. use memoise cache result. effective \\(R_t\\) estimates compared consensus values SPI-M-O group (red):  EpiEstim \\(R_t\\) fits comparison data, infectivity profile much certain exhibit oscillation due weekly periodicity underlying time series.","code":"ggplot2::ggplot()+   ggplot2::geom_errorbar(     data = growthrates::covid_infectivity_profile %>% tidyr::complete(time=0:max(time), fill = list(probability=0)),     mapping = ggplot2::aes(x=as.factor(time),ymin=probability,ymax=probability),     width=1,     colour=\"blue\",     alpha=0.1   )+   ggplot2::geom_line(     data = growthrates::covid_infectivity_profile %>%        dplyr::group_by(time) %>%       dplyr::summarise(m = mean(probability)) %>%        dplyr::ungroup(),     mapping = ggplot2::aes(x=as.factor(time),y=m, group=1),     inherit.aes = FALSE   ) # .cache = memoise::cache_filesystem(rappdirs::user_cache_dir(\"growthrates\")) #  # cached_rt_from_growth_rate = memoise::memoise( #   growthrates::rt_from_growth_rate, #   cache = .cache # )  rt_fit = fit %>% growthrates::rt_from_growth_rate(ip = covid_infectivity_profile)  plot_rt(rt_fit, events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(0.6,1.6))+   ggplot2::geom_errorbar(data=england_consensus_rt,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. rt_epi_fit = tmp %>% growthrates::rt_epiestim(ip = covid_infectivity_profile)  plot_rt(rt_epi_fit, events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(0.6,1.6))+   ggplot2::geom_errorbar(data=england_consensus_rt,ggplot2::aes(x=date-7,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one."},{"path":"/articles/covid-timeseries.html","id":"prevalence-and-growth-rate-from-test-positivity-rates","dir":"Articles","previous_headings":"","what":"Prevalence and growth rate from test positivity rates","title":"England COVID-19 cases","text":"Test availability consistent pandemic. early stages PCR tests difficult obtain case positive incidence estimates thought vast underestimate. cetain parts pandemic targetted testing high risk groups occurred. Test positivity different view pandemic accounts biases introduces others . data must contain denom column case represents number tests conducted:  case gradient proportion logistic scale estimate growth rate. senses relative growth testing effort case produces answer similar incidence model.  similar growth rate estimates method can also theoretically used calculate estimates \\(R_t\\). Growth-proportion phase diagrams can also compare different points times see elsewhere, different populations.","code":"england_covid_pcr_positivity %>% dplyr::glimpse() ## Rows: 1,413 ## Columns: 4 ## $ date  <date> 2023-12-12, 2023-12-11, 2023-12-10, 2023-12-09, 2023-12-08, 202… ## $ time  <time_prd> 1444, 1443, 1442, 1441, 1440, 1439, 1438, 1437, 1436, 1435,… ## $ count <dbl> 375, 509, 381, 350, 445, 399, 430, 457, 413, 295, 252, 293, 343,… ## $ denom <dbl> 1707, 5884, 5514, 6001, 7840, 8333, 8946, 10139, 9805, 6445, 638… fit2 = england_covid_pcr_positivity %>%    growthrates::proportion_locfit_model()  plot_proportion(fit2, england_covid_pcr_positivity, events = england_events, size=0.25, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\"))) plot_growth_rate(fit2, events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=england_consensus_growth_rate,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. plot_growth_phase(fit2,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7,     colour=\"blue\" )"},{"path":"/articles/covid-timeseries.html","id":"nhs-covid-app","dir":"Articles","previous_headings":"","what":"NHS COVID app","title":"England COVID-19 cases","text":"NHS covid app performed digital contact tracing. rate venue check-ins demonstrates levels high risk social contacts however became optional Aug 2021. Self isolation alerts peaked Aug / Sept 2021 Delta wave Dec 2021 / Jan 2022 Omicron wave. Periods rapid growth preceed increases NHS app notifications. (N.B. data https://www.gov.uk/government/publications/nhs-covid-19-app-statistics)","code":"p1 = plot_incidence(fit,events = england_events, colour=\"blue\", date_breaks=\"3 months\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")))+   ggplot2::facet_wrap(~\"Cases\")+   ggplot2::theme(axis.text.x.bottom = ggplot2::element_blank())+   scale_y_log1p()  p2 = plot_growth_rate(fit,events = england_events, colour=\"blue\", date_breaks=\"3 months\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=england_consensus_growth_rate,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\")+   ggplot2::facet_wrap(~\"Growth rate\")+   ggplot2::theme(axis.text.x.bottom = ggplot2::element_blank(),axis.text.x.top = ggplot2::element_blank()) ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. p3 = ggplot2::ggplot(growthrates::england_nhs_app)+   geom_events(events=england_events,hide_labels = TRUE)+   ggplot2::geom_step(ggplot2::aes(x=date, y=alerts/mean(alerts, na.rm=TRUE),colour=\"alerts\"))+   ggplot2::geom_step(ggplot2::aes(x=date, y=visits/mean(visits, na.rm=TRUE),colour=\"venue visits\"))+   ggplot2::geom_rect(ggplot2::aes(xmin=date,xmax=dplyr::lead(date), ymin=0, ymax=alerts/mean(alerts, na.rm=TRUE),fill=\"alerts\"), linewidth=0, alpha=0.2)+   ggplot2::geom_rect(ggplot2::aes(xmin=date,xmax=dplyr::lead(date), ymin=0, ymax=visits/mean(visits, na.rm=TRUE),fill=\"venue visits\"), linewidth=0, alpha=0.2)+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")))+   ggplot2::ylab(\"relative frequency\")+   ggplot2::xlab(NULL)+   ggplot2::facet_wrap(~\"NHS app\")+   ggplot2::scale_color_brewer(palette=\"Dark2\", name=NULL, aesthetics = c(\"fill\",\"colour\"))+   ggplot2::scale_x_date(date_breaks=\"3 months\",date_labels = \"%b %y\")+   ggplot2::theme(legend.position = \"bottom\")  p1+p2+p3+patchwork::plot_layout(ncol=1) ## Warning: Removed 63 rows containing missing values or values outside the scale range ## (`geom_step()`). ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_rect()`). ## Warning: Removed 63 rows containing missing values or values outside the scale range ## (`geom_rect()`)."},{"path":[]},{"path":"/articles/estimators-example.html","id":"simple-incidence-test-with-a-poisson-model","dir":"Articles","previous_headings":"Locfit models","what":"Simple incidence test with a poisson model","title":"Simulation tests for growth rate estimators","text":"incidence mode based absolute counts:  Estimted absolute growth rate versus simulation (red)","code":"data = .test_data() data %>% dplyr::glimpse() #> Rows: 105 #> Columns: 5 #> $ time  <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1… #> $ r     <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,… #> $ rate  <dbl> 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, 182.2119, 201.… #> $ count <int> 105, 104, 145, 150, 168, 174, 207, 217, 247, 273, 296, 353, 355,… #> $ denom <dbl> 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2402… tmp = data %>% poisson_locfit_model(window=7, deg = 2)  plot_incidence(tmp, data)+ggplot2::geom_line(   mapping=ggplot2::aes(x=as.Date(time),y=rate), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_rate(tmp)+   ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=r), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_phase(tmp) #> Warning in .time_labels(x, ..., dfmt = dfmt, ifmt = ifmt, na.value = na.value): #> labelling applied to non-integer times."},{"path":"/articles/estimators-example.html","id":"multinomial-data","dir":"Articles","previous_headings":"Locfit models","what":"Multinomial data","title":"Simulation tests for growth rate estimators","text":"Multiple classes simulated 3 independent epdiemics (‘variant1’, ‘variant2’ ‘variant3’) known growth rates initial sample size resulting 3 parallel time series. combined give overall epidemic proportional distribution ‘variant’ fraction whole. relative growth rate calculated based set parameters.","code":"data2 = .test_multinomial() %>% dplyr::group_by(class) %>% dplyr::glimpse() #> Rows: 315 #> Columns: 9 #> Groups: class [3] #> $ time           <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, … #> $ r              <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, … #> $ rate           <dbl> 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, 182.2… #> $ count          <int> 105, 104, 145, 150, 168, 174, 207, 217, 247, 273, 296, … #> $ denom          <dbl> 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2402, 2… #> $ class          <chr> \"variant1\", \"variant1\", \"variant1\", \"variant1\", \"varian… #> $ proportion     <dbl> 0.3382826, 0.3420088, 0.3445125, 0.3458146, 0.3459542, … #> $ proportion.obs <dbl> 0.3398058, 0.3421053, 0.3452381, 0.3456221, 0.3449692, … #> $ relative.r     <dbl> 0.019385523, 0.013833622, 0.008404115, 0.003151554, -0.…"},{"path":"/articles/estimators-example.html","id":"poisson-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"Poisson model","title":"Simulation tests for growth rate estimators","text":"Firstly fitting incidence model groupwise fashion:  absolute growth rates:","code":"tmp2 = data2 %>% poisson_locfit_model(window=7, deg = 1)  plot_incidence(tmp2, data2)+scale_y_log1p() plot_growth_rate(modelled = tmp2)+    ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=r, colour=class), data=data2, inherit.aes = FALSE)+    ggplot2::facet_wrap(dplyr::vars(class), ncol=1)"},{"path":"/articles/estimators-example.html","id":"one-versus-others-binomial-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"One versus others Binomial model","title":"Simulation tests for growth rate estimators","text":"looks proportions three variants growth rate relative : Firstly proportions:  secondly relative growth rate:","code":"# This will reinterpret total to be the total of positives across all variants data3 = data2 %>%    dplyr::group_by(time) %>%    dplyr::mutate(denom = sum(count)) %>%   dplyr::group_by(class) %>%   dplyr::glimpse() #> Rows: 315 #> Columns: 9 #> Groups: class [3] #> $ time           <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, … #> $ r              <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, … #> $ rate           <dbl> 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, 182.2… #> $ count          <int> 105, 104, 145, 150, 168, 174, 207, 217, 247, 273, 296, … #> $ denom          <int> 309, 304, 420, 434, 487, 504, 604, 638, 734, 823, 909, … #> $ class          <chr> \"variant1\", \"variant1\", \"variant1\", \"variant1\", \"varian… #> $ proportion     <dbl> 0.3382826, 0.3420088, 0.3445125, 0.3458146, 0.3459542, … #> $ proportion.obs <dbl> 0.3398058, 0.3421053, 0.3452381, 0.3456221, 0.3449692, … #> $ relative.r     <dbl> 0.019385523, 0.013833622, 0.008404115, 0.003151554, -0.… tmp3 = data3 %>% proportion_locfit_model(window=14, deg = 2)  plot_proportion(modelled = tmp3,raw = data3)+   ggplot2::facet_wrap(dplyr::vars(class), ncol=1) plot_growth_rate(modelled = tmp3)+    ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=relative.r, colour=class), data=data2, inherit.aes = FALSE)+    ggplot2::facet_wrap(dplyr::vars(class), ncol=1) plot_growth_phase(tmp3) #> Warning in .time_labels(x, ..., dfmt = dfmt, ifmt = ifmt, na.value = na.value): #> labelling applied to non-integer times."},{"path":"/articles/estimators-example.html","id":"multinomial-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"Multinomial model","title":"Simulation tests for growth rate estimators","text":"mulitnomial model gives us absolute proportions (growth rates)","code":"# we don't need to calculate the denominator as it is done automatically by the  # mulitnomial model  tmp4 = data2 %>% multinomial_nnet_model() #> # weights:  30 (18 variable) #> initial  value 361707.109921  #> iter  10 value 182309.592690 #> iter  20 value 178948.204365 #> final  value 176994.905787  #> converged plot_multinomial(tmp4) # plot_multinomial(tmp3, events = event_test,normalise = TRUE)"},{"path":[]},{"path":"/articles/estimators-example.html","id":"poisson-model-1","dir":"Articles","previous_headings":"GLM models","what":"Poisson model","title":"Simulation tests for growth rate estimators","text":"Spline currently good incidence","code":"tmp5 = data %>% poisson_glm_model(window=7) plot_incidence(tmp5,data)"},{"path":"/articles/estimators-example.html","id":"binomial-model","dir":"Articles","previous_headings":"GLM models","what":"Binomial model","title":"Simulation tests for growth rate estimators","text":"Absolute proportions ","code":"tmp6 = data3 %>% proportion_glm_model(window=14, deg = 2) plot_proportion(tmp6,data3)"},{"path":"/articles/incidence-trends.html","id":"incidence-poisson-rate-model","dir":"Articles","previous_headings":"","what":"Incidence Poisson rate model","title":"Population comparisons and incidence","text":"plot normalised incidence rates COVID-19 population size, shows initially rate COVID cases highest elderly. late 2020 pattern changed rates uniform accross age groups. early 2021 vaccination took hold school testing rolled , younger age groups higher rates COVID positive tests, curious spike young age groups around November 2021. early 2022 pattern reversed elderly became age group highest rates, pattern persisted present.  use test positives proxy COVID incidence clearlly potentially biased testing (partilcularly first wave testing limited hospital). reliable comparison situation test positivie proportion, unfortunately testing rates published broken age. exponential growth rate already normalised population size. Comparisons growth rate populations gives idea tightly coupled . age groups epidemic growing shrinking sync apart possibly young. COVID detections age group particularly reliable though easy -interpret.  combination growth normalised incidence allows us compare epidemic state different time points, case Christmas day 2020, 2021 2022. shows data previous graphs.","code":"tmp = growthrates::england_covid %>%    growthrates::poisson_locfit_model(window=21) %>%    growthrates::normalise_incidence(growthrates::england_demographics)  raw_pop = growthrates::england_covid %>% dplyr::inner_join(england_demographics, by=\"class\")  plot_incidence(tmp,raw = raw_pop, size=0.25)+scale_y_log1p(n=7)+   ggplot2::scale_colour_viridis_d(aesthetics = c(\"fill\",\"colour\")) plot_growth_rate(tmp)+   ggplot2::scale_fill_viridis_d(aesthetics = c(\"fill\",\"colour\"))+   ggplot2::coord_cartesian(ylim=c(-0.15,0.15)) #> Coordinate system already present. Adding new coordinate system, which will #> replace the existing one. plot_growth_phase(tmp,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7 )+   ggplot2::scale_colour_viridis_d()"},{"path":"/articles/incidence-trends.html","id":"proportion-model","dir":"Articles","previous_headings":"","what":"Proportion model","title":"Population comparisons and incidence","text":"two possible proportions models woudl interest . mentioned proportion positive tests age group give us clearer picture whether differences age groups differential testing, unfortunately available data set. second potential use distribution ages test positive age group. age distribution gives us information burden disease population also biased test prioritisation. multinomial proportion shows similar patterns normalised incidence plot :  age distribution test positives can normalised age distribution population. give us relative proportion age groups people testing positive versus expected population. conceptually relative risk age group given COVID status .e. \\(\\frac{P(age = 80+|COVID+)}{P(age = 80+)}\\) point time given population quantity centred around 1 comparing growth rate gives us possibly clearer picture trajectory relative distribution COVID population. Xmas 2021 although majority cases young, relatively high growth elderly population meant catching , can see early 2022 elderly highest COVID positive rates. 2022 however, separation age groups established trajectories acting preserve separation.","code":"tmp2 = growthrates::england_covid %>%    growthrates::proportion_locfit_model(window=21)  p1 = plot_multinomial(tmp2,normalise = TRUE)+   ggplot2::scale_fill_viridis_d()  p2 = ggplot2::ggplot(england_demographics)+   ggplot2::geom_bar(ggplot2::aes(x=\"baseline\",y=population/sum(population)*100,fill=class), stat=\"identity\", position=\"stack\", colour=\"black\", linewidth=0.1)+   ggplot2::scale_fill_viridis_d(guide=\"none\")+   ggplot2::xlab(NULL)+   ggplot2::ylab(NULL)+   ggplot2::theme(axis.text.y = ggplot2::element_blank())+   ggplot2::coord_cartesian(expand=FALSE)  p1+p2+patchwork::plot_layout(nrow=1,widths = c(20,1),guides = \"collect\") tmp3 = tmp2 %>% normalise_proportion(england_demographics)  plot_growth_phase(tmp3,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7 )+   ggplot2::scale_colour_viridis_d() #> Coordinate system already present. Adding new coordinate system, which will #> replace the existing one."},{"path":"/articles/incidence-trends.html","id":"todo","dir":"Articles","previous_headings":"","what":"TODO:","title":"Population comparisons and incidence","text":"Regional breakdown testing effort positivity age group published part test trace. -age -region breakdown, shut test trace. https://www.gov.uk/government/publications/weekly-statistics--nhs-test--trace-england-2--15-june-2022 look age group proportion incidence models look ascertainment bias age groups.","code":"prop = growthrates::england_covid_proportion %>%   growthrates::proportion_locfit_model(window=5)  plot_proportion(prop)+ggplot2::scale_fill_viridis_d(aesthetics = c(\"colour\",\"fill\")) tmp_pop = growthrates::england_covid_proportion %>% dplyr::select(class,population) %>% dplyr::distinct() pois = growthrates::england_covid_proportion %>%   growthrates::poisson_locfit_model(window=5) %>%   growthrates::normalise_incidence(tmp_pop)  plot_incidence(pois)+ggplot2::scale_fill_viridis_d(aesthetics = c(\"colour\",\"fill\"))"},{"path":"/articles/rt-from-incidence.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating the reproduction number from modelled incidence","text":"estimated incidence disease \\(I_t\\) using poisson rate using maximum likelihood estimators, rate typically log-normally distributed parameters \\(\\mu\\) \\(\\sigma\\). fitted model shown log1p scale, COVID-19 epidemic England:  appealing use modelled incidence estimate calculate estimate reproduction number, \\(R_t\\). Incidence models can derived number ways, easily inspected error can made tolerant missing values outliers.","code":""},{"path":"/articles/rt-from-incidence.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Estimating the reproduction number from modelled incidence","text":"use modelled estimate incidence predict \\(R_t\\) need propagate uncertainty incidence \\(R_t\\) estimates. calculate \\(R_t\\) can use backwards-looking renewal equations incorporate infectivity profile disease (\\(\\omega\\)) number days infection (\\(\\tau\\)): \\[ I_t \\sim Lognormal(\\mu_t,\\sigma_t) \\\\ R_t = \\frac{I_t}{\\sum_{\\tau}{\\omega_{\\tau}I_{t-\\tau}}} \\] giving us: \\[ R_t = \\frac{Lognormal(\\mu_t,\\sigma_t)}{\\sum_{\\tau}{   Lognormal( \\mu_{t-\\tau} + log(\\omega_{\\tau}) , \\sigma_{t-\\tau}) }} \\\\ \\] sum \\(\\) log normal distributions can approximated another log normal (Lo 2013) parameters \\(\\mu_Z\\) \\(\\sigma_Z\\). \\[ \\begin{align}     S_+ &= \\operatorname{E}\\left[\\sum_i X_i \\right] = \\sum_i     \\operatorname{E}[X_i] =     \\sum_i e^{\\mu_i + \\sigma_i^2/2}     \\\\     \\sigma^2_{Z} &= 1/S_+^2 \\, \\sum_{,j}       \\operatorname{cor}_{ij} \\sigma_i \\sigma_j \\operatorname{E}[X_i] \\operatorname{E}[X_j] =       1/S_+^2 \\, \\sum_{,j}       \\operatorname{cor}_{ij} \\sigma_i \\sigma_j e^{\\mu_i+\\sigma_i^2/2}       e^{\\mu_j+\\sigma_j^2/2}     \\\\     \\mu_Z &= \\ln\\left( S_+ \\right) - \\sigma_{Z}^2/2 \\end{align} \\] sum term denominator renewal equations consists set correlated scaled log normal distributions scale correlation defined infectivity profile (\\(\\omega\\)). case \\(cor_{ij}\\) can equated infectivity profile (\\(\\omega_{|-j|}\\)) \\(\\neq j\\) 1 \\(= j\\). \\(\\mu_i\\) \\(\\mu_{t-\\tau} + ln(\\omega_{\\tau})\\). \\[ \\begin{align}     S_{t} &= \\sum_{s=1}^{|\\omega|} { \\omega_s e^{\\mu_{t-s} + \\sigma_{t-s}^2/2 }} \\\\     \\sigma_{Z,t} &= \\sqrt{       \\frac{         \\sum_{,j=1}^{|\\omega|} {         (\\omega_{|-j|}+(,j)) \\omega_i \\omega_j (\\sigma_{(t-)} e^{\\mu_{(t-)}+\\sigma_{(t-)}^2/2}) (\\sigma_{(t-j)} e^{\\mu_{(t-j)}+\\sigma_{(t-j)}^2/2)}         }       }{S_{t}^2}     }   \\\\     \\mu_{Z,t} &= \\log\\left( S_{t} \\right) - \\sigma_{Z,t}^2/2 \\end{align} \\] \\(\\mu\\) central estimate case counts log scale, standard deviation can also large. numerical stability issues dealing terms involving \\(e^{(\\mu+\\sigma^2)}\\), however keeping everything log space using optimised log-sum-exp functions can made computationally tractable. \\[ \\begin{align}     \\log(S_{t}) &= \\log(\\sum_{s=1}^{|\\omega|} {  e^{\\mu_{t-s} + \\sigma_{t-s}^2/2 + \\log(\\omega_s) }}) \\\\     \\log(T_{t,\\tau}) &= \\log(\\omega_{\\tau}) + \\log(\\sigma_{(t-{\\tau})}) + \\mu_{(t-{\\tau})} + \\sigma_{(t-{\\tau})}^2/2) \\\\     \\log(cor_{,j}) &= \\log(\\omega_{|-j|}+(=j)) \\\\     \\log(\\sigma_{Z,t}^2) &= \\log(         \\sum_{,j=1}^{|\\omega|} {           e^{             \\log(cor_{,j}) + \\log(T_{t,}) + \\log(T_{t,j})           }         }) - 2 \\log(S_{t}) \\\\     \\mu_{Z,t} &= \\log( S_{t} ) - \\sigma_{Z,t}^2/2 \\end{align} \\] N.B. assume individual estimates incidence uncorrelated simplifies : \\[ \\begin{align} \\log(\\sigma_{Z,t}^2) &= \\log(         \\sum_{\\tau=1}^{|\\omega|} {           e^{             2 \\log(T_{t,\\tau})           }         }) - 2 \\log(S_{t}) \\end{align} \\] Empirically huge amount difference estimates two forms. infectivity profile \\(\\omega\\) spread large period correlation matrix \\(O(\\omega)^2\\) may predicate simpler order 1 formulation. \\(\\mu_{Z,t}\\) \\(\\sigma_{Z,t}\\) left final derivation \\(R_t\\), giving us distributional form \\(R_t\\) incorporating uncertainty modelled incidence estimates: \\[ \\begin{align} R_t &= \\frac{Lognormal(\\mu_t,\\sigma_t)} {Lognormal( \\mu_{Z,t}, \\sigma_{Z,t})} \\\\ \\mu_{R_t} &= \\mu_t - \\mu_{Z,t} \\\\ \\sigma_{R_t} &= \\sqrt{\\sigma_t^2+\\sigma_{z,t}^2} \\\\ R_t &= Lognormal(\\mu_{R_t}, \\sigma_{R_t}) \\end{align} \\] conditioned single known infectivity profile. reality also uncertainty infectivity profile, however assume particular distributional form . can use range empirical estimates infectivity profile calculate multiple distributional estimates \\(R_t\\) combine mixture distribution numerically. avoid computation involved however reasonable approximation mixture log normal mean variance mixture, likely individual \\(R_t\\) estimates similar. moment matching done using mean variance \\(R_t\\) distributions log transformed distribution parameters, \\(\\mu\\) \\(\\sigma\\): \\[ \\begin{align} E[R_t] &= e^{(\\mu_{R_t} - \\sigma_{R_t}^2/2)} \\\\ Var[R_t] &= \\big[   e^{(\\sigma_{R_t}^2)} - 1 \\big] \\big[   e^{2 \\mu_{R_t} + \\sigma_{R_t}^2} \\big] \\\\ E[R_t^*] &= \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} E[{R_t|\\omega}] \\\\ Var[R_t^*] &= \\frac{1}{|\\Omega|} \\bigg(\\sum_{\\omega \\\\Omega}{Var[R_t|\\omega]+E[R_t|\\omega]^2}\\bigg) - E[R_t^*]^2 \\\\ \\mu^* &= \\log\\Bigg(\\frac{E[R_t^*]}{\\sqrt{\\frac{Var[R_t^*]}{E[R_t^*]^2}+1}}\\Bigg)  \\\\ \\sigma_*^2 &= \\log\\bigg(\\frac{Var[R_t^*]}{E[R_t^*]^2}+1\\bigg)\\\\ R_t^* &= Lognormal(\\mu_*,\\sigma_*) \\end{align} \\]","code":""},{"path":"/articles/rt-from-incidence.html","id":"implementation","dir":"Articles","previous_headings":"","what":"Implementation","title":"Estimating the reproduction number from modelled incidence","text":"method implemented using following R function, designed numerical stability speed. Generating \\(R_t\\) estimates given modelled incidence typically occurring :","code":"#> function (mu, sigma, omega, mu_t, sigma_t, cor = TRUE)  #> { #>     omega_m = as.matrix(omega) #>     omega_m = apply(omega_m, MARGIN = 2, rev) #>     tmp = apply(omega_m, MARGIN = 2, function(omega) { #>         log_S_t = .logsumexp(mu_t + sigma_t^2/2 + log(omega)) #>         log_T_t_tau = mu_t + sigma_t^2/2 + log(omega) + log(sigma_t) #>         if (cor) { #>             n = length(omega) #>             idx = 0:(n^2 - 1) #>             i = idx%/%n #>             j = idx%%n #>             log_cor_ij = c(0, log(omega))[abs(i - j) + 1] #>             log_var_Zt_ij = log_cor_ij + log_T_t_tau[i + 1] +  #>                 log_T_t_tau[j + 1] #>         } #>         else { #>             log_var_Zt_ij = 2 * log_T_t_tau #>         } #>         log_var_Zt = .logsumexp(log_var_Zt_ij) - 2 * log_S_t #>         var_Zt = exp(log_var_Zt) #>         mu_Zt = log_S_t - var_Zt/2 #>         return(c(mu_Rt = mu - mu_Zt, var_Rt = sigma^2 + var_Zt)) #>     }) #>     if (ncol(tmp) == 1) { #>         mu_star = tmp[1] #>         sigma2_star = tmp[2] #>         mean_star = exp(mu_star + sigma2_star/2) #>         var_star = (exp(sigma2_star) - 1) * exp(2 * mu_star +  #>             sigma2_star) #>     } #>     else { #>         means = exp(tmp[1, ] + tmp[2, ]/2) #>         vars = (exp(tmp[2, ]) - 1) * exp(2 * tmp[1, ] + tmp[2,  #>             ]) #>         mean_star = mean(means) #>         var_star = mean(vars + means^2) - mean_star^2 #>         mu_star = log(mean_star/sqrt((var_star/mean_star^2) +  #>             1)) #>         sigma2_star = log((var_star/mean_star^2) + 1) #>     } #>     sigma_star = sqrt(sigma2_star) #>     return(tibble::tibble(rt.mu = mu_star, rt.sigma = sigma_star,  #>         rt.fit = mean_star, rt.se.fit = sqrt(var_star), rt.0.025 = stats::qlnorm(0.025,  #>             mu_star, sigma_star), rt.0.5 = stats::qlnorm(0.5,  #>             mu_star, sigma_star), rt.0.975 = stats::qlnorm(0.975,  #>             mu_star, sigma_star))) #> } #> <bytecode: 0x614726aa12a8> #> <environment: namespace:growthrates>"},{"path":"/articles/rt-from-incidence.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"Estimating the reproduction number from modelled incidence","text":"Testing incidence model shown , comparing results SPI-M-O consensus \\(R_t\\) estimates gives us following time-series England. formally evaluated qualitatively good fit. single time series 1410 time points took around 3 seconds fit, opens possibility performing \\(R_t\\) estimates fine grained geographical demographic subgroups.","code":"#>    user  system elapsed  #>   2.413   0.002   2.415"},{"path":"/articles/rt-from-incidence.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating the reproduction number from modelled incidence","text":"present methodology deriving \\(R_t\\) modelled estimates incidence propagating uncertainty. demonstrate produces satisfactory qualitative results COVID-19 data. method relatively quick, fully deterministic, can used top statistical models estimating incidence use logarithmic link functions.","code":""},{"path":"/articles/time-periods.html","id":"line-lists-vs--time-series","dir":"Articles","previous_headings":"","what":"Line lists vs. time series","title":"Data wrangling and working with `growthrates`","text":"Infectious disease data usually either comes set observations individual infection time stamp (.e. line list) count events (e.g. positive tests, hospitalisations, deaths) happening within specific period (day, week, month etc.) time series. count data may also denominator known. testing number tests performed, number patients risk hospitalisation. data types may also class associated observation, defining subgroup infections interest. variant virus, age group, example. may make sense compare different subgroups . case denominator may total counts among groups per unit time. Additionally may information size population subgroup. growthrates assumes part input data form set time series counts, unique set times, usually complete. create datasets like line lists growthrates provides infrastructure dealing time series:","code":""},{"path":"/articles/time-periods.html","id":"time-periods","dir":"Articles","previous_headings":"","what":"Time periods","title":"Data wrangling and working with `growthrates`","text":"weekly case rate represents time slice seven days start finish date. Dates continuous quantity, cut_dates() can used classify continuous dates periods equal duration, start date: Performing calculations using interval censored dates awkward. numeric version dates useful can keep track start date time series intrinsic duration, numeric. purpose time_period class: time_period defaults using date beginning COVID-19 pandemic origin calculating duration unit based data (case weekly). usual set S3 methods available formatting, printing, labelling, casting time_periods dates POSIXct classes: weekly time series can recast different frequency, start date: original dates recoverable: date_seq() can used make sure set periodic times complete: time_periods can used monthly yearly data data regular. handled irregular date periods generally OK use growthrates functions like date_seq may work anticipated irregular dates. Two time series can aligned make comparable:","code":"random_dates = Sys.Date()+sample.int(21,50,replace = TRUE) cut_date( random_dates, unit = \"1 week\", anchor = \"start\", dfmt = \"%d %b\") #> 03 May — 09 May 03 May — 09 May 26 Apr — 02 May 26 Apr — 02 May 10 May — 16 May  #>    \"2024-05-03\"    \"2024-05-03\"    \"2024-04-26\"    \"2024-04-26\"    \"2024-05-10\"  #> 10 May — 16 May 26 Apr — 02 May 26 Apr — 02 May 03 May — 09 May 26 Apr — 02 May  #>    \"2024-05-10\"    \"2024-04-26\"    \"2024-04-26\"    \"2024-05-03\"    \"2024-04-26\"  #> 26 Apr — 02 May 10 May — 16 May 03 May — 09 May 26 Apr — 02 May 03 May — 09 May  #>    \"2024-04-26\"    \"2024-05-10\"    \"2024-05-03\"    \"2024-04-26\"    \"2024-05-03\"  #> 03 May — 09 May 26 Apr — 02 May 10 May — 16 May 03 May — 09 May 26 Apr — 02 May  #>    \"2024-05-03\"    \"2024-04-26\"    \"2024-05-10\"    \"2024-05-03\"    \"2024-04-26\"  #> 26 Apr — 02 May 26 Apr — 02 May 10 May — 16 May 26 Apr — 02 May 26 Apr — 02 May  #>    \"2024-04-26\"    \"2024-04-26\"    \"2024-05-10\"    \"2024-04-26\"    \"2024-04-26\"  #> 03 May — 09 May 26 Apr — 02 May 10 May — 16 May 26 Apr — 02 May 03 May — 09 May  #>    \"2024-05-03\"    \"2024-04-26\"    \"2024-05-10\"    \"2024-04-26\"    \"2024-05-03\"  #> 03 May — 09 May 10 May — 16 May 26 Apr — 02 May 10 May — 16 May 10 May — 16 May  #>    \"2024-05-03\"    \"2024-05-10\"    \"2024-04-26\"    \"2024-05-10\"    \"2024-05-10\"  #> 26 Apr — 02 May 26 Apr — 02 May 26 Apr — 02 May 10 May — 16 May 03 May — 09 May  #>    \"2024-04-26\"    \"2024-04-26\"    \"2024-04-26\"    \"2024-05-10\"    \"2024-05-03\"  #> 26 Apr — 02 May 10 May — 16 May 10 May — 16 May 26 Apr — 02 May 03 May — 09 May  #>    \"2024-04-26\"    \"2024-05-10\"    \"2024-05-10\"    \"2024-04-26\"    \"2024-05-03\"  #> 26 Apr — 02 May 03 May — 09 May 10 May — 16 May 10 May — 16 May 03 May — 09 May  #>    \"2024-04-26\"    \"2024-05-03\"    \"2024-05-10\"    \"2024-05-10\"    \"2024-05-03\" dates = seq(as.Date(\"2020-01-01\"),by=7,length.out = 5) tmp = as.time_period(dates) #> No `start_date` (or `anchor`) specified. Using default: 2019-12-29 #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S tmp #> time unit: week, origin: 2019-12-29 (a Sunday) #> [1] 0.4285714 1.4285714 2.4285714 3.4285714 4.4285714 suppressWarnings(labels(tmp)) #> 01/Jan — 07/Jan #> 08/Jan — 14/Jan #> 15/Jan — 21/Jan #> 22/Jan — 28/Jan #> 29/Jan — 04/Feb tmp2 = as.time_period(tmp, unit = \"2 days\", start_date = \"2020-01-01\") tmp2 #> time unit: 2 days, origin: 2020-01-01 (a Wednesday) #> [1]  0.0  3.5  7.0 10.5 14.0 as.Date(tmp2) #> [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" tmp3 = as.time_period(Sys.Date()+c(0:2,4:5)*7,anchor = \"start\") #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S as.Date(date_seq(tmp3)) #> [1] \"2024-04-25\" \"2024-05-02\" \"2024-05-09\" \"2024-05-16\" \"2024-05-23\" #> [6] \"2024-05-30\" orig_dates = Sys.Date()+1:10*7  # a 2 daily time series based on weekly dates t1 = as.time_period(orig_dates, unit = \"2 days\", start_date = \"2021-01-01\") t1 #> time unit: 2 days, origin: 2021-01-01 (a Friday) #>  [1] 608.5 612.0 615.5 619.0 622.5 626.0 629.5 633.0 636.5 640.0  # a weekly with different start date t2 = as.time_period(orig_dates, unit = \"1 week\", start_date = \"2022-01-01\") t2 #> time unit: week, origin: 2022-01-01 (a Saturday) #>  [1] 121.7143 122.7143 123.7143 124.7143 125.7143 126.7143 127.7143 128.7143 #>  [9] 129.7143 130.7143  # rebase t1 into the same format as t2 # as t1 and t2 based on the same original dates converting t2 onto the same # peridicty as t1 results in an identical set of times t3 = as.time_period(t1,t2) t3 #> time unit: week, origin: 2022-01-01 (a Saturday) #>  [1] 121.7143 122.7143 123.7143 124.7143 125.7143 126.7143 127.7143 128.7143 #>  [9] 129.7143 130.7143"},{"path":"/articles/time-periods.html","id":"times-in-growthrates-and-conversion-of-line-lists","dir":"Articles","previous_headings":"","what":"Times in growthrates and conversion of line-lists","title":"Data wrangling and working with `growthrates`","text":"growthrates uses time_period class internally extensively. Casting dates time_periods generally needs done using growthrates. functions growthrates operate time series data expect unique (usually complete) set data periodic time. help prepare line-list data time series time_summarise() function. minimal line-list date column nothing else. line-list contains class column interpreted complete record possible options can calculate denominator. case positive negative results test: specific example subsequent analysis growthrates may focus positive subgroup , comparison positive negative test results trivial. another example class may test results, major subdivision e.g. variant disease. case comparison different groups may much relevant. use class major sub-group convenience. Additional grouping class columns also possible multi-facetted comparisons, grouping preserved included automatically denominator, may need manually calculated:","code":"random_dates = Sys.Date()+sample.int(21,50,replace = TRUE) linelist = tibble::tibble(date = random_dates) linelist %>% time_summarise(unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 3 #> Columns: 2 #> $ time  <time_prd> 0, 1, 2 #> $ count <int> 27, 17, 6 random_dates = Sys.Date()+sample.int(21,200,replace = TRUE) linelist2 = tibble::tibble(   date = random_dates,   class = stats::rbinom(200, 1, 0.04) %>% ifelse(\"positive\",\"negative\") ) linelist2 %>% time_summarise(unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 6 #> Columns: 4 #> Groups: class [2] #> $ class <chr> \"negative\", \"negative\", \"negative\", \"positive\", \"positive\", \"pos… #> $ time  <time_prd> 0, 1, 2, 0, 1, 2 #> $ count <int> 52, 66, 73, 4, 2, 3 #> $ denom <int> 56, 68, 76, 56, 68, 76 random_dates = Sys.Date()+sample.int(21,200,replace = TRUE) variant = apply(stats::rmultinom(200, 1, c(0.1,0.3,0.6)), MARGIN = 2, function(x) which(x==1))  linelist3 = tibble::tibble(   date = random_dates,   class = c(\"variant1\",\"variant2\",\"variant3\")[variant],   gender = ifelse(stats::rbinom(200,1,0.5),\"male\",\"female\") )    count_by_gender = linelist3 %>%    dplyr::group_by(gender) %>%    time_summarise(unit=\"1 week\") %>%    dplyr::arrange(time, gender, class) %>%   dplyr::glimpse() #> Rows: 18 #> Columns: 5 #> Groups: gender, class [6] #> $ gender <chr> \"female\", \"female\", \"female\", \"male\", \"male\", \"male\", \"female\",… #> $ class  <chr> \"variant1\", \"variant2\", \"variant3\", \"variant1\", \"variant2\", \"va… #> $ time   <time_prd> 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2 #> $ count  <int> 5, 12, 17, 2, 5, 26, 4, 8, 24, 1, 8, 25, 3, 10, 25, 7, 6, 12 #> $ denom  <int> 34, 34, 34, 33, 33, 33, 36, 36, 36, 34, 34, 34, 38, 38, 38…"},{"path":"/articles/time-periods.html","id":"aggregating-time-series-datasets-","dir":"Articles","previous_headings":"","what":"Aggregating time series datasets.","title":"Data wrangling and working with `growthrates`","text":"case time series additional grouping present, removing level grouping whilst retaining time made easier time_aggregate(). case wish sum count denom gender, retaining class grouping. default time_aggregate sum count, denom population columns behaviour can specified passing dplyr::summarise style directives function.","code":"count_by_gender %>%    dplyr::group_by(class,gender) %>%    time_aggregate() %>%   dplyr::glimpse() #> Rows: 9 #> Columns: 4 #> Groups: class [3] #> $ class <chr> \"variant1\", \"variant1\", \"variant1\", \"variant2\", \"variant2\", \"var… #> $ time  <time_prd> 0, 1, 2, 0, 1, 2, 0, 1, 2 #> $ count <int> 7, 5, 10, 17, 16, 16, 43, 49, 37 #> $ denom <int> 67, 70, 63, 67, 70, 63, 67, 70, 63"},{"path":"/articles/variant-proportions.html","id":"covid-19-proportions-in-england","dir":"Articles","previous_headings":"","what":"COVID-19 proportions in England","title":"Multinomial proportions models for genomic variants","text":"Sanger Centre & COGUK performed large amount sequencing COVID-19 pandemic, identify emerging genomic variants. scaled second half 2021 continued beginning 2023. Lineages assigned using Pango lineage system important ones given nicknames . Sanger variants data discontinued, still available download. code download, process data sets determine full lineage data-raw/variants.R file, output bundled data set . many caveats data terms bias regarded definitive: data must class column defining main categorisation data (case main pango variant). time column time_period derived date (weekly). necessary column count column integer counts class. data must grouped class. Multiple models can fitted simultaneously data grouped columns.","code":"# tidy copy of the sanger weekly variants count data aggregated to England level growthrates::england_variants %>% dplyr::glimpse() ## Rows: 479 ## Columns: 6 ## Groups: class [10] ## $ date      <date> 2020-09-05, 2020-09-05, 2020-09-12, 2020-09-12, 2020-09-19,… ## $ time      <time_prd> 0, 0, 7, 7, 14, 14, 21, 21, 28, 28, 35, 35, 42, 42, 49,… ## $ class     <fct> Other, Alpha (B.1.1.7), Other, Alpha (B.1.1.7), Other, Alpha… ## $ who_class <fct> Other, Alpha, Other, Alpha, Other, Alpha, Other, Alpha, Othe… ## $ count     <dbl> 1182, 371, 1439, 588, 837, 429, 1685, 1157, 1208, 823, 1501,… ## $ denom     <dbl> 1553, 1553, 2027, 2027, 1266, 1266, 2842, 2842, 2031, 2031, …"},{"path":"/articles/variant-proportions.html","id":"multinomial-proportions-model-","dir":"Articles","previous_headings":"","what":"Multinomial proportions model.","title":"Multinomial proportions models for genomic variants","text":"Genomic testing happened subset cases. testing effort varied significantly time. frequency variant time can determined multinomial model.","code":"# debug(estimate_multinomial_proportion) # devtools::load_all() probs = england_variants %>%    multinomial_nnet_model(window = 28) ## # weights:  40 (27 variable) ## initial  value 3583520.087982  ## iter  10 value 1562162.620103 ## iter  20 value 1380207.974678 ## iter  30 value 959088.555894 ## iter  40 value 742507.401941 ## iter  50 value 731767.878774 ## iter  60 value 729647.595794 ## iter  70 value 726795.599521 ## iter  80 value 716309.104988 ## iter  90 value 709310.965531 ## iter 100 value 707285.575109 ## final  value 707285.575109  ## stopped after 100 iterations plot_multinomial(probs)+   ggplot2::scale_fill_viridis_d(option=\"cividis\")"},{"path":"/articles/variant-proportions.html","id":"binomial-proportions-model","dir":"Articles","previous_headings":"","what":"Binomial proportions model","title":"Multinomial proportions models for genomic variants","text":"binomial proportions different multinomial probabilities calculated , come confidence intervals, however median values necessarily sum 1.  rate change proportion individual variant versus others logistic scale can used work exponential growth rate one variant relative others. relative growth rate taken togehter esimates variants given time centred around zero. one variant growth advantage, definition others growth disadvantage despite potentially causing larger disease burden increasing numbers growing epidemic.  binomial relative growth rate per day growth advantage existing variants. dependency unit time controlled time_period configuration. data provided time_period defined daily basis despite data provided weekly. Doubling time make strict sense describing relative growth rates shown .","code":"probs2 = england_variants %>% proportion_locfit_model(window = 14)  plot_proportion(probs2)+   ggplot2::scale_colour_viridis_d(option=\"cividis\",aesthetics = c(\"colour\",\"fill\")) plot_growth_rate(probs2) +   ggplot2::scale_fill_viridis_d(option=\"cividis\",aesthetics = c(\"colour\",\"fill\"))"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert Challen. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Challen R (2024). growthrates: Estimate Incidence, Proportions Exponential Growth Rates. R package version 0.1.3,  https://github.com/bristol-vaccine-centre/growthrates, https://doi.org/10.5281/zenodo.7242761, https://bristol-vaccine-centre.github.io/growthrates/.","code":"@Manual{,   title = {growthrates: Estimate Incidence, Proportions and Exponential Growth Rates},   author = {Robert Challen},   year = {2024},   note = {R package version 0.1.3,  https://github.com/bristol-vaccine-centre/growthrates, https://doi.org/10.5281/zenodo.7242761},   url = {https://bristol-vaccine-centre.github.io/growthrates/}, }"},{"path":"/index.html","id":"growthrates","dir":"","previous_headings":"","what":"Estimate Incidence, Proportions and Exponential Growth Rates","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"Simple statistical models visualisations calculating incidence, proportion, exponential growth rate, reproduction number infectious disease case time series. tool kit largely developed COVID-19 pandemic.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"Bristol Vaccine Centre r-universe. Installation follows: can install development version growthrates GitHub :","code":"options(repos = c(   \"bristol-vaccine-centre\" = 'https://bristol-vaccine-centre.r-universe.dev/',   CRAN = 'https://cloud.r-project.org'))  # Download and install growthrates in R install.packages(\"growthrates\") # install.packages(\"devtools\") devtools::install_github(\"bristol-vaccine-centre/growthrates\")"},{"path":"/reference/as.Date.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert time period to dates — as.Date.time_period","title":"Convert time period to dates — as.Date.time_period","text":"Convert time period dates","code":""},{"path":"/reference/as.Date.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert time period to dates — as.Date.time_period","text":"","code":"# S3 method for time_period as.Date(x, ...)  # S3 method for time_period as.POSIXct(x, ...)"},{"path":"/reference/as.Date.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert time period to dates — as.Date.time_period","text":"x time_period ... used","code":""},{"path":"/reference/as.Date.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert time period to dates — as.Date.time_period","text":"vector dates representing start input time_period entries","code":""},{"path":"/reference/as.Date.time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convert time period to dates — as.Date.time_period","text":".POSIXct(time_period): Convert vector POSIXct","code":""},{"path":"/reference/as.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to a time period class — as.time_period","title":"Convert to a time period class — as.time_period","text":"Time periods just zero based numeric representation dates time unit baked . allows variable length periods (e.g. days weeks), fractional days represented consistent(ish) way","code":""},{"path":"/reference/as.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to a time period class — as.time_period","text":"","code":"as.time_period(x, unit = NULL, start_date = NULL, anchor = NULL, ...)  # S3 method for time_period c(..., recursive = F)  # S3 method for time_period [(x, ...)  # S3 method for time_period [(x, ...) <- value  # S3 method for time_period [[(x, ...)  # S3 method for time_period [[(x, ...) <- value  is.time_period(x)  # S3 method for time_period print(x, ...)"},{"path":"/reference/as.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to a time period class — as.time_period","text":"x vector numbers (may integer real) time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return new time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date recalibrated use new start date. anchor relevant x vector dates start_date specified, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x find reference date time-series. NULL start_date also NULL fall back getOption(\"day_zero\",\"2019-12-29\") ... used subtype implementations recursive concatenate recursively value value","code":""},{"path":"/reference/as.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to a time period class — as.time_period","text":"time_period class, consisting vector numbers, attributes time period start_date","code":""},{"path":"/reference/as.time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convert to a time period class — as.time_period","text":"c(time_period): Combine time_period [: Subset time_period `[`(time_period) <- value: Assign values subset time_period [[: Get value time_period `[[`(time_period) <- value: Assign value time_period .time_period(): Check time_period print(time_period): Print time_period","code":""},{"path":"/reference/as.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert to a time period class — as.time_period","text":"","code":"# 100 weeks from 2020-01-01  tmp = as.time_period(0:100, 7, \"2020-01-01\") as.Date(tmp) #>   [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" #>   [6] \"2020-02-05\" \"2020-02-12\" \"2020-02-19\" \"2020-02-26\" \"2020-03-04\" #>  [11] \"2020-03-11\" \"2020-03-18\" \"2020-03-25\" \"2020-04-01\" \"2020-04-08\" #>  [16] \"2020-04-15\" \"2020-04-22\" \"2020-04-29\" \"2020-05-06\" \"2020-05-13\" #>  [21] \"2020-05-20\" \"2020-05-27\" \"2020-06-03\" \"2020-06-10\" \"2020-06-17\" #>  [26] \"2020-06-24\" \"2020-07-01\" \"2020-07-08\" \"2020-07-15\" \"2020-07-22\" #>  [31] \"2020-07-29\" \"2020-08-05\" \"2020-08-12\" \"2020-08-19\" \"2020-08-26\" #>  [36] \"2020-09-02\" \"2020-09-09\" \"2020-09-16\" \"2020-09-23\" \"2020-09-30\" #>  [41] \"2020-10-07\" \"2020-10-14\" \"2020-10-21\" \"2020-10-28\" \"2020-11-04\" #>  [46] \"2020-11-11\" \"2020-11-18\" \"2020-11-25\" \"2020-12-02\" \"2020-12-09\" #>  [51] \"2020-12-16\" \"2020-12-23\" \"2020-12-30\" \"2021-01-06\" \"2021-01-13\" #>  [56] \"2021-01-20\" \"2021-01-27\" \"2021-02-03\" \"2021-02-10\" \"2021-02-17\" #>  [61] \"2021-02-24\" \"2021-03-03\" \"2021-03-10\" \"2021-03-17\" \"2021-03-24\" #>  [66] \"2021-03-31\" \"2021-04-07\" \"2021-04-14\" \"2021-04-21\" \"2021-04-28\" #>  [71] \"2021-05-05\" \"2021-05-12\" \"2021-05-19\" \"2021-05-26\" \"2021-06-02\" #>  [76] \"2021-06-09\" \"2021-06-16\" \"2021-06-23\" \"2021-06-30\" \"2021-07-07\" #>  [81] \"2021-07-14\" \"2021-07-21\" \"2021-07-28\" \"2021-08-04\" \"2021-08-11\" #>  [86] \"2021-08-18\" \"2021-08-25\" \"2021-09-01\" \"2021-09-08\" \"2021-09-15\" #>  [91] \"2021-09-22\" \"2021-09-29\" \"2021-10-06\" \"2021-10-13\" \"2021-10-20\" #>  [96] \"2021-10-27\" \"2021-11-03\" \"2021-11-10\" \"2021-11-17\" \"2021-11-24\" #> [101] \"2021-12-01\"  range(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> [1]   0 100 min(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> [1] 0 tmp2 = as.integer(as.Date(tmp)) # testthat::expect_true(all(na.omit(tmp2-lag(tmp2)) == 7))  tmp2 = as.time_period(0:23, 1/24, \"2020-01-01\") as.POSIXct(tmp2) #>  [1] \"2020-01-01 00:00:00 GMT\" \"2020-01-01 01:00:00 GMT\" #>  [3] \"2020-01-01 02:00:00 GMT\" \"2020-01-01 03:00:00 GMT\" #>  [5] \"2020-01-01 04:00:00 GMT\" \"2020-01-01 05:00:00 GMT\" #>  [7] \"2020-01-01 06:00:00 GMT\" \"2020-01-01 07:00:00 GMT\" #>  [9] \"2020-01-01 08:00:00 GMT\" \"2020-01-01 09:00:00 GMT\" #> [11] \"2020-01-01 10:00:00 GMT\" \"2020-01-01 11:00:00 GMT\" #> [13] \"2020-01-01 12:00:00 GMT\" \"2020-01-01 13:00:00 GMT\" #> [15] \"2020-01-01 14:00:00 GMT\" \"2020-01-01 15:00:00 GMT\" #> [17] \"2020-01-01 16:00:00 GMT\" \"2020-01-01 17:00:00 GMT\" #> [19] \"2020-01-01 18:00:00 GMT\" \"2020-01-01 19:00:00 GMT\" #> [21] \"2020-01-01 20:00:00 GMT\" \"2020-01-01 21:00:00 GMT\" #> [23] \"2020-01-01 22:00:00 GMT\" \"2020-01-01 23:00:00 GMT\"  # convert timeseries to new \"unit\" tmp = as.time_period(0:100, 7, \"2020-01-01\") tmp2 = as.time_period(tmp,1) testthat::expect_equal(as.numeric(tmp2), 0:100*7)"},{"path":"/reference/breaks_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A scales breaks generator for log1p scales — breaks_log1p","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"scales breaks generator log1p scales","code":""},{"path":"/reference/breaks_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"","code":"breaks_log1p(n = 5, base = 10)"},{"path":"/reference/breaks_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"n number breaks base base breaks","code":""},{"path":"/reference/breaks_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"function ggplot scale breaks","code":""},{"path":"/reference/breaks_log1p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"","code":"ggplot2::ggplot(ggplot2::diamonds, ggplot2::aes(x=price))+   ggplot2::geom_density()+   ggplot2::scale_x_continuous(trans=\"log1p\", breaks=breaks_log1p())"},{"path":"/reference/covid_infectivity_profile.html","id":null,"dir":"Reference","previous_headings":"","what":"The covid_infectivity_profile dataframe structure specification — covid_infectivity_profile","title":"The covid_infectivity_profile dataframe structure specification — covid_infectivity_profile","text":"covid_infectivity_profile dataframe structure specification","code":""},{"path":"/reference/covid_infectivity_profile.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The covid_infectivity_profile dataframe structure specification — covid_infectivity_profile","text":"dataframe containing following columns: boot (anything) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period time Must grouped : boot (exactly). default value defined.","code":""},{"path":"/reference/cut_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Places a set of dates within a regular time series — cut_date","title":"Places a set of dates within a regular time series — cut_date","text":"counterpart date_seq_dates(). Take original set data place within regular time series periodicity time series may expressed numbers days, weeks, months quarters, years, periods defined anchoring date, day week reference start end input dates. can either return periods dates factors (e.g. plotting) time_period analysis relies numeric representation date duration anchor.","code":""},{"path":"/reference/cut_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Places a set of dates within a regular time series — cut_date","text":"","code":"cut_date(   dates,   unit,   anchor = \"start\",   output = c(\"date\", \"factor\", \"time_period\"),   dfmt = \"%d/%b/%y\",   ifmt = \"{start} — {end}\",   ... )"},{"path":"/reference/cut_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Places a set of dates within a regular time series — cut_date","text":"dates set dates unit period e.g. \"1 week\" anchor one date, \"start\" \"end\" weekday name e.g. \"mon\" always one start time periods cutting output return result either \"date\" (default), ordered \"factor\" date ranges label, \"time_period\". result named labels referring dfmt strptime format dates labels ifmt sprintf format period label containing %s exactly twice. ... ignored","code":""},{"path":"/reference/cut_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Places a set of dates within a regular time series — cut_date","text":"set dates, times factor level, representing start period date falls , period defined duration anchor","code":""},{"path":"/reference/cut_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Places a set of dates within a regular time series — cut_date","text":"","code":"dates = as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-03\",NA)) fs = growthrates::date_seq(dates, \"2 days\") dates - cut_date(dates, \"2 days\") #> Time differences in days #> 01/Jan/20 — 02/Jan/20 31/Jan/20 — 01/Feb/20 15/Jan/20 — 16/Jan/20  #>                     0                     1                     0  #> 02/Feb/20 — 03/Feb/20               Unknown  #>                     1                    NA  cut_date(dates,unit=\"2 days\", output=\"time_period\") #> time unit: 2 days, origin: 2020-01-01 (a Wednesday) #> [1]  0 15  7 16 NA  # A weekly set of dates: dates2 = Sys.Date() + floor(stats::runif(50,max=10))*7  # in this specific situation the final date is not truncated because the # input data is seen as an exact match for the whole output period. cut_date(dates2, \"1 week\", \"sun\", output=\"factor\") #>  [1] 21/Apr/24 — 27/Apr/24 16/Jun/24 — 22/Jun/24 02/Jun/24 — 08/Jun/24 #>  [4] 28/Apr/24 — 04/May/24 21/Apr/24 — 27/Apr/24 19/May/24 — 25/May/24 #>  [7] 19/May/24 — 25/May/24 05/May/24 — 11/May/24 09/Jun/24 — 15/Jun/24 #> [10] 09/Jun/24 — 15/Jun/24 16/Jun/24 — 22/Jun/24 28/Apr/24 — 04/May/24 #> [13] 21/Apr/24 — 27/Apr/24 12/May/24 — 18/May/24 19/May/24 — 25/May/24 #> [16] 28/Apr/24 — 04/May/24 19/May/24 — 25/May/24 21/Apr/24 — 27/Apr/24 #> [19] 12/May/24 — 18/May/24 23/Jun/24 — 29/Jun/24 05/May/24 — 11/May/24 #> [22] 02/Jun/24 — 08/Jun/24 09/Jun/24 — 15/Jun/24 28/Apr/24 — 04/May/24 #> [25] 23/Jun/24 — 29/Jun/24 09/Jun/24 — 15/Jun/24 21/Apr/24 — 27/Apr/24 #> [28] 26/May/24 — 01/Jun/24 02/Jun/24 — 08/Jun/24 02/Jun/24 — 08/Jun/24 #> [31] 21/Apr/24 — 27/Apr/24 05/May/24 — 11/May/24 12/May/24 — 18/May/24 #> [34] 02/Jun/24 — 08/Jun/24 19/May/24 — 25/May/24 19/May/24 — 25/May/24 #> [37] 09/Jun/24 — 15/Jun/24 23/Jun/24 — 29/Jun/24 28/Apr/24 — 04/May/24 #> [40] 05/May/24 — 11/May/24 02/Jun/24 — 08/Jun/24 19/May/24 — 25/May/24 #> [43] 02/Jun/24 — 08/Jun/24 02/Jun/24 — 08/Jun/24 21/Apr/24 — 27/Apr/24 #> [46] 09/Jun/24 — 15/Jun/24 09/Jun/24 — 15/Jun/24 23/Jun/24 — 29/Jun/24 #> [49] 23/Jun/24 — 29/Jun/24 12/May/24 — 18/May/24 #> 11 Levels: 21/Apr/24 — 27/Apr/24 < ... < 30/Jun/24 — 06/Jul/24 cut_date(dates2, dfmt = \"%d/%b\", output=\"factor\", unit = \"2 weeks\", anchor=\"sun\") #>  [1] 21/Apr — 04/May 16/Jun — 29/Jun 02/Jun — 15/Jun 21/Apr — 04/May #>  [5] 21/Apr — 04/May 19/May — 01/Jun 19/May — 01/Jun 05/May — 18/May #>  [9] 02/Jun — 15/Jun 02/Jun — 15/Jun 16/Jun — 29/Jun 21/Apr — 04/May #> [13] 21/Apr — 04/May 05/May — 18/May 19/May — 01/Jun 21/Apr — 04/May #> [17] 19/May — 01/Jun 21/Apr — 04/May 05/May — 18/May 16/Jun — 29/Jun #> [21] 05/May — 18/May 02/Jun — 15/Jun 02/Jun — 15/Jun 21/Apr — 04/May #> [25] 16/Jun — 29/Jun 02/Jun — 15/Jun 21/Apr — 04/May 19/May — 01/Jun #> [29] 02/Jun — 15/Jun 02/Jun — 15/Jun 21/Apr — 04/May 05/May — 18/May #> [33] 05/May — 18/May 02/Jun — 15/Jun 19/May — 01/Jun 19/May — 01/Jun #> [37] 02/Jun — 15/Jun 16/Jun — 29/Jun 21/Apr — 04/May 05/May — 18/May #> [41] 02/Jun — 15/Jun 19/May — 01/Jun 02/Jun — 15/Jun 02/Jun — 15/Jun #> [45] 21/Apr — 04/May 02/Jun — 15/Jun 02/Jun — 15/Jun 16/Jun — 29/Jun #> [49] 16/Jun — 29/Jun 05/May — 18/May #> 6 Levels: 21/Apr — 04/May < 05/May — 18/May < ... < 30/Jun — 13/Jul"},{"path":"/reference/date_seq.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a date vector to the full range of possible dates — date_seq.Date","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"Derive vector observation dates, complete ordered sequence periods regular time series, length periods specified, number od days, weeks, years etc. E.g. can convert random set dates ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/date_seq.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"# S3 method for Date date_seq(x, period = .day_interval(x), anchor = \"start\", complete = FALSE, ...)"},{"path":"/reference/date_seq.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"x vector dates, possibly including NA values period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. anchor defines day appears sequence (extend far). Given either date, \"start\", \"end\" day week, e.g. \"mon\". complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/date_seq.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"vector dates regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/date_seq.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"date_seq(as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-01\",NA)), \"2 days\") #>  [1] \"2020-01-01\" \"2020-01-03\" \"2020-01-05\" \"2020-01-07\" \"2020-01-09\" #>  [6] \"2020-01-11\" \"2020-01-13\" \"2020-01-15\" \"2020-01-17\" \"2020-01-19\" #> [11] \"2020-01-21\" \"2020-01-23\" \"2020-01-25\" \"2020-01-27\" \"2020-01-29\" #> [16] \"2020-01-31\""},{"path":"/reference/date_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — date_seq","title":"Create the full sequence of values in a vector — date_seq","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/date_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — date_seq","text":"","code":"date_seq(x, period, ...)"},{"path":"/reference/date_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — date_seq","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. ... subtype methods","code":""},{"path":"/reference/date_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — date_seq","text":"vector type input","code":""},{"path":"/reference/date_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — date_seq","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/date_seq.numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — date_seq.numeric","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/date_seq.numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"","code":"# S3 method for numeric date_seq(x, period = 1, tol = 1e-06, ...)"},{"path":"/reference/date_seq.numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. tol Numerical tolerance checking periodicity. ... subtype methods","code":""},{"path":"/reference/date_seq.numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"vector type input","code":""},{"path":"/reference/date_seq.numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/date_seq.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a time_period vector to the full range of possible times — date_seq.time_period","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"Derive vector observation time_periods, complete ordered sequence periods regular time series, length periods specified, number days, weeks, years etc. E.g. can convert random set times ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/date_seq.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"# S3 method for time_period date_seq(x, period = attributes(x)$unit, complete = FALSE, ...)"},{"path":"/reference/date_seq.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"x time period vector period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/date_seq.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"vector time_periods regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/date_seq.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"tmp = as.time_period(c(0,10,100), 7, \"2020-01-01\") date_seq(tmp, \"7 days\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #>  [1]   0  10  20  30  40  50  60  70  80  90 100"},{"path":"/reference/date_to_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a set of dates to numeric timepoints — date_to_time","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"Using start_date unit specification","code":""},{"path":"/reference/date_to_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"","code":"date_to_time(   dates,   unit = .day_interval(dates),   start_date = getOption(\"day_zero\", \"2019-12-29\") )"},{"path":"/reference/date_to_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"dates vector dates convert unit specification unit resulting time series. determined periodicity dates specified. another time_period given unit start_date origin conversion. Defaults beginning COVID pandemic","code":""},{"path":"/reference/date_to_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"vector class time_period","code":""},{"path":"/reference/date_to_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"","code":"times = date_to_time(as.Date(\"2019-12-29\")+0:100, \"1 week\") dates = time_to_date(times)"},{"path":"/reference/doubling_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubling time from growth rate — doubling_time","title":"Doubling time from growth rate — doubling_time","text":"unit doubling times always days.","code":""},{"path":"/reference/doubling_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubling time from growth rate — doubling_time","text":"","code":"doubling_time(x, ...)"},{"path":"/reference/doubling_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubling time from growth rate — doubling_time","text":"x dataframe calculated either proportion incidence growth rate calculations: e.g. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value. ... used","code":""},{"path":"/reference/doubling_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubling time from growth rate — doubling_time","text":"dataframe additional columns doubling time relative doubling time plus confidence intervals.","code":""},{"path":"/reference/doubling_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubling time from growth rate — doubling_time","text":"","code":"growthrates::england_covid %>%   growthrates::poisson_locfit_model(window=21) %>%   growthrates::doubling_time() %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 15 #> Groups: class [19] #> $ class               <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 0… #> $ time                <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,… #> $ incidence.fit       <dbl> -17.891227, -17.395804, -16.873590, -16.331042, -1… #> $ incidence.se.fit    <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358, 1.8681… #> $ incidence.0.025     <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, 1.950766… #> $ incidence.0.5       <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, 8.081996… #> $ incidence.0.975     <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, 3.348359… #> $ growth.fit          <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723… #> $ growth.se.fit       <dbl> 0.05395200, 0.05584978, 0.05729669, 0.05835042, 0.… #> $ growth.0.025        <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097, 0.3565… #> $ growth.0.5          <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723… #> $ growth.0.975        <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391, 0.5880… #> $ doubling_time.0.5   <dbl> 1.444431, 1.446200, 1.451072, 1.458415, 1.467596, … #> $ doubling_time.0.025 <dbl> 1.183613, 1.177315, 1.174868, 1.175545, 1.178641, … #> $ doubling_time.0.975 <dbl> 1.852682, 1.874256, 1.897059, 1.920556, 1.944248, …"},{"path":"/reference/england_consensus_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","title":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","text":"SPI-M-O used range different statistical mechanistic models produce estimates growth rate epidemic various data sources (including early version growthrates).","code":""},{"path":"/reference/england_consensus_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","text":"","code":"data(england_consensus_growth_rate)"},{"path":"/reference/england_consensus_growth_rate.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","text":"dataframe containing following columns: date (date) - date estimate low (numeric) - lower published estimate growth rate high (numeric) - higher published estimate growth rate mandatory groupings. default value. 111 rows 3 columns","code":""},{"path":"/reference/england_consensus_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"The SPI-M-O England consensus reproduction number — england_consensus_rt","title":"The SPI-M-O England consensus reproduction number — england_consensus_rt","text":"SPI-M-O used range different statistical mechanistic models produce estimates  reproduction number epidemic various data sources.","code":""},{"path":"/reference/england_consensus_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The SPI-M-O England consensus reproduction number — england_consensus_rt","text":"","code":"data(england_consensus_rt)"},{"path":"/reference/england_consensus_rt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The SPI-M-O England consensus reproduction number — england_consensus_rt","text":"dataframe containing following columns: date (date) - date estimate low (numeric) - lower published estimate reproduction number high (numeric) - higher published estimate reproduction number mandatory groupings. default value. 113 rows 3 columns","code":""},{"path":"/reference/england_covid.html","id":null,"dir":"Reference","previous_headings":"","what":"Daily COVID-19 case counts by age group in England — england_covid","title":"Daily COVID-19 case counts by age group in England — england_covid","text":"dataset daily count covid cases age group England downloaded UKHSA coronavirus API, formatted use growthrates. denominator calculated overall positive count age groups. data set can used calculate group-wise incidence absolute growth rates group wise proportions relative growth rates.","code":""},{"path":"/reference/england_covid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Daily COVID-19 case counts by age group in England — england_covid","text":"","code":"data(england_covid)"},{"path":"/reference/england_covid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Daily COVID-19 case counts by age group in England — england_covid","text":"dataframe containing following columns: date (.Date) - date column class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column count (numeric) - count column denom (numeric) - denom column time (.time_period) - time column Must grouped : class (groupings allowed). default value. 26790 rows 5 columns","code":""},{"path":"/reference/england_covid_pcr_positivity.html","id":null,"dir":"Reference","previous_headings":"","what":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","title":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","text":"coronavirus.gov.uk dashboard published tests conducted positive results separate data sets range geographies. case data combined testing rate denominator, positives count England.","code":""},{"path":"/reference/england_covid_pcr_positivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","text":"","code":"data(england_covid_pcr_positivity)"},{"path":"/reference/england_covid_pcr_positivity.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","text":"dataframe containing following columns: date (date) - daily time series time (.time_period) - time column count (numeric) - test positives denom (numeric) - total tests mandatory groupings. default value. 1413 rows 4 columns","code":""},{"path":"/reference/england_covid_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"England COVID by age group for ascertainment — england_covid_proportion","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"age group stratified dataset ","code":""},{"path":"/reference/england_covid_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"","code":"data(england_covid_proportion)"},{"path":"/reference/england_covid_proportion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"dataframe containing following columns: class (character) - age group date (date) - start date week count (numeric) - count COVID positives denom (numeric) - number COVID tests performed population (numeric) - size population age group time (.time_period) - time column (weekly) Must grouped : class (groupings allowed). default value. 1050 rows 6 columns","code":""},{"path":"/reference/england_covid_proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"coronavirus.gov.uk site positive cases aggregated 10 year age groups weekly time. NHS test trace date reported regional age group testing effort aggregated country level. ONS 2021 census population aggregated 10 year age groups.","code":""},{"path":"/reference/england_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"England demographics — england_demographics","title":"England demographics — england_demographics","text":"Population counts 5 year age group England 2021 census.","code":""},{"path":"/reference/england_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England demographics — england_demographics","text":"","code":"data(england_demographics)"},{"path":"/reference/england_demographics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England demographics — england_demographics","text":"dataframe containing following columns: class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column population (numeric) - population column baseline_proportion (numeric) - baseline_proportion column Must grouped : class (groupings allowed). default value. 19 rows 3 columns","code":""},{"path":"/reference/england_demographics.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"England demographics — england_demographics","text":"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationandhouseholdestimatesenglandandwalescensus2021/census2021/census2021firstresultsenglandwales1.xlsx","code":""},{"path":"/reference/england_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Key dated in the COVID-19 response in England — england_events","title":"Key dated in the COVID-19 response in England — england_events","text":"includes mainly dates lockdowns, releases social distancing measures dates new variants first detected.","code":""},{"path":"/reference/england_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Key dated in the COVID-19 response in England — england_events","text":"","code":"data(england_events)"},{"path":"/reference/england_events.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Key dated in the COVID-19 response in England — england_events","text":"dataframe containing following columns: label (character) - label column start (date) - start column end (date) - end column mandatory groupings. default value. 13 rows 3 columns","code":""},{"path":"/reference/england_nhs_app.html","id":null,"dir":"Reference","previous_headings":"","what":"NHS COVID-19 app data — england_nhs_app","title":"NHS COVID-19 app data — england_nhs_app","text":"check-(social activity) alerts (self isolation instruction) data NHS COVID-19 app, aggregated country level week week basis.","code":""},{"path":"/reference/england_nhs_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NHS COVID-19 app data — england_nhs_app","text":"","code":"data(england_nhs_app)"},{"path":"/reference/england_nhs_app.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NHS COVID-19 app data — england_nhs_app","text":"dataframe containing following columns: date (date) - start date week alerts (integer) - count self-isolation alerts visits (integer) - number venue check-ins representing visits social venues. time (.time_period) - time column mandatory groupings. default value. 137 rows 4 columns","code":""},{"path":"/reference/england_variants.html","id":null,"dir":"Reference","previous_headings":"","what":"Counts of COVID-19 variants — england_variants","title":"Counts of COVID-19 variants — england_variants","text":"Data COG-UK Sanger centre sequencing programme. data made available Welcome foundation Lower tier local authority level, weekly timeseries counts per variant. Variants assigned using tree structure Pango lineage. Different sub-lineages aggregated major variants concern.","code":""},{"path":"/reference/england_variants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Counts of COVID-19 variants — england_variants","text":"","code":"data(england_variants)"},{"path":"/reference/england_variants.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Counts of COVID-19 variants — england_variants","text":"dataframe containing following columns: date (date) - end date week time (.time_period) - time column class (enum(,Alpha (B.1.1.7),Delta (B.1.617.2),Delta (AY.4),Omicron (),Omicron (BA.2),Omicron (BA.4),Omicron (BA.5),XBB (),Kraken (XBB.1.5),Arcturus (XBB.1.16),Eris (EG.5.1))) - class column who_class (enum(,Alpha,Delta,Omicron,Kraken,Arcturus,Eris)) - who_class column count (numeric) - weekly count column denom (numeric) - number sequences performed week Must grouped : class (groupings allowed). default value. 479 rows 6 columns","code":""},{"path":"/reference/fdmy.html","id":null,"dir":"Reference","previous_headings":"","what":"Format date as dmy — fdmy","title":"Format date as dmy — fdmy","text":"Format date dmy","code":""},{"path":"/reference/fdmy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format date as dmy — fdmy","text":"","code":"fdmy(date)"},{"path":"/reference/fdmy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format date as dmy — fdmy","text":"date date convert","code":""},{"path":"/reference/fdmy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format date as dmy — fdmy","text":"formatted date","code":""},{"path":"/reference/fdmy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format date as dmy — fdmy","text":"","code":"fdmy(Sys.Date()) #> [1] \"25 Apr 2024\""},{"path":"/reference/full_seq.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a date vector to the full range of possible dates — date_seq.Date","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"Derive vector observation dates, complete ordered sequence periods regular time series, length periods specified, number od days, weeks, years etc. E.g. can convert random set dates ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/full_seq.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"# S3 method for Date date_seq(x, period = .day_interval(x), anchor = \"start\", complete = FALSE, ...)"},{"path":"/reference/full_seq.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"x vector dates, possibly including NA values period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. anchor defines day appears sequence (extend far). Given either date, \"start\", \"end\" day week, e.g. \"mon\". complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/full_seq.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"vector dates regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/full_seq.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"date_seq(as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-01\",NA)), \"2 days\") #>  [1] \"2020-01-01\" \"2020-01-03\" \"2020-01-05\" \"2020-01-07\" \"2020-01-09\" #>  [6] \"2020-01-11\" \"2020-01-13\" \"2020-01-15\" \"2020-01-17\" \"2020-01-19\" #> [11] \"2020-01-21\" \"2020-01-23\" \"2020-01-25\" \"2020-01-27\" \"2020-01-29\" #> [16] \"2020-01-31\""},{"path":"/reference/full_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — full_seq","title":"Create the full sequence of values in a vector — full_seq","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/full_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — full_seq","text":"","code":"date_seq(x, period, ...)"},{"path":"/reference/full_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — full_seq","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. ... subtype methods","code":""},{"path":"/reference/full_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — full_seq","text":"vector type input","code":""},{"path":"/reference/full_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — full_seq","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/full_seq.numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — full_seq.numeric","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/full_seq.numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"","code":"# S3 method for numeric date_seq(x, period = 1, tol = 1e-06, ...)"},{"path":"/reference/full_seq.numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. tol Numerical tolerance checking periodicity. ... subtype methods","code":""},{"path":"/reference/full_seq.numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"vector type input","code":""},{"path":"/reference/full_seq.numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/full_seq.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a time_period vector to the full range of possible times — date_seq.time_period","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"Derive vector observation time_periods, complete ordered sequence periods regular time series, length periods specified, number days, weeks, years etc. E.g. can convert random set times ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/full_seq.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"# S3 method for time_period date_seq(x, period = attributes(x)$unit, complete = FALSE, ...)"},{"path":"/reference/full_seq.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"x time period vector period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/full_seq.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"vector time_periods regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/full_seq.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"tmp = as.time_period(c(0,10,100), 7, \"2020-01-01\") date_seq(tmp, \"7 days\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #>  [1]   0  10  20  30  40  50  60  70  80  90 100"},{"path":"/reference/geom_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Add time series event markers to a timeseries plot. — geom_events","title":"Add time series event markers to a timeseries plot. — geom_events","text":"x axis must date.","code":""},{"path":"/reference/geom_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add time series event markers to a timeseries plot. — geom_events","text":"","code":"geom_events(   events = i_events,   event_label_size = 7,   event_label_colour = \"black\",   event_label_angle = -30,   event_line_colour = \"grey50\",   event_fill_colour = \"grey50\",   hide_labels = FALSE,   guide_axis = ggplot2::derive(),   ... )"},{"path":"/reference/geom_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add time series event markers to a timeseries plot. — geom_events","text":"events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined. event_label_size big make event label event_label_colour event label colour event_label_angle event label colour event_line_colour event line colour event_fill_colour event area fill hide_labels show labels guide_axis guide axis configuration labels (see ggplot2::guide_axis ggplot2::dup_axis). can used specify position amongst things. ... Arguments passed ggplot2::scale_x_date name name scale. Used axis legend title. waiver(), default, name scale taken first mapping used aesthetic. NULL, legend title omitted. breaks One : NULL breaks waiver() breaks specified date_breaks Date/POSIXct vector giving positions breaks function takes limits input returns breaks output date_breaks string giving distance breaks like \"2 weeks\", \"10 years\". breaks date_breaks specified, date_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. labels One : NULL labels waiver() default labels computed transformation object character vector giving labels (must length breaks) expression vector (must length breaks). See ?plotmath details. function takes breaks input returns labels output. Also accepts rlang lambda function notation. date_labels string giving formatting specification labels. Codes defined strftime(). labels date_labels specified, date_labels wins. minor_breaks One : NULL breaks waiver() breaks specified date_minor_breaks Date/POSIXct vector giving positions minor breaks function takes limits input returns minor breaks output date_minor_breaks string giving distance minor breaks like \"2 weeks\", \"10 years\". minor_breaks date_minor_breaks specified, date_minor_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. limits One : NULL use default scale range numeric vector length two providing limits scale. Use NA refer existing minimum maximum function accepts existing (automatic) limits returns new limits. Also accepts rlang lambda function notation. Note setting limits positional scales remove data outside limits. purpose zoom, use limit argument coordinate system (see coord_cartesian()). expand position scales, vector range expansion constants used add padding around data ensure placed distance away axes. Use convenience function expansion() generate values expand argument. defaults expand scale 5% side continuous variables, 0.6 units side discrete variables. oob One : Function handles limits outside scale limits (bounds). Also accepts rlang lambda function notation. default (scales::censor()) replaces bounds values NA. scales::squish() squishing bounds values range. scales::squish_infinite() squishing infinite values range. guide function used create guide name. See guides() information. position position scales, position axis. left right y axes, top bottom x axes.","code":""},{"path":"/reference/geom_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add time series event markers to a timeseries plot. — geom_events","text":"set geoms timeseries.","code":""},{"path":"/reference/germany_covid.html","id":null,"dir":"Reference","previous_headings":"","what":"Weekly COVID-19 case counts by age group in Germany — germany_covid","title":"Weekly COVID-19 case counts by age group in Germany — germany_covid","text":"dataset weekly count covid cases age group Germany downloaded Robert Koch Institute Survstat service, formatted use growth rates. denominator calculated overall positive count age groups. data set can used calculate group-wise incidence absolute growth rates group wise proportions relative growth rates.","code":""},{"path":"/reference/germany_covid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weekly COVID-19 case counts by age group in Germany — germany_covid","text":"","code":"data(germany_covid)"},{"path":"/reference/germany_covid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Weekly COVID-19 case counts by age group in Germany — germany_covid","text":"dataframe containing following columns: class (enum(0–14,15–19,20–24,25–29,30–39,40–49,50–59,60–69,70–79,80+,Unknown, .ordered=TRUE)) - class column date (.Date) - date column count (integer) - count column time (.time_period) - time column denom (integer) - denom column Must grouped : class (groupings allowed). default value. 2070 rows 6 columns","code":""},{"path":"/reference/germany_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"Germany demographics — germany_demographics","title":"Germany demographics — germany_demographics","text":"Derived Robert Koch Survstat service comparing counts incidence rates.","code":""},{"path":"/reference/germany_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Germany demographics — germany_demographics","text":"","code":"data(germany_demographics)"},{"path":"/reference/germany_demographics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Germany demographics — germany_demographics","text":"dataframe containing following columns: class (enum(0–14,15–19,20–24,25–29,30–39,40–49,50–59,60–69,70–79,80+, .ordered=TRUE)) - class column population (integer) - population column Must grouped : class (groupings allowed). default value. 10 rows 2 columns","code":""},{"path":"/reference/is.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether vector is a date — is.Date","title":"Check whether vector is a date — is.Date","text":"Check whether vector date","code":""},{"path":"/reference/is.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether vector is a date — is.Date","text":"","code":"is.Date(x)"},{"path":"/reference/is.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether vector is a date — is.Date","text":"x vector check","code":""},{"path":"/reference/is.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether vector is a date — is.Date","text":"TRUE dates, FALSE otherwise","code":""},{"path":"/reference/is.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether vector is a date — is.Date","text":"","code":"is.Date(Sys.Date()) #> [1] TRUE"},{"path":"/reference/labels.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Label a time period — labels.time_period","title":"Label a time period — labels.time_period","text":"Create set labels time period based start duration period. format configurable using start end dates dfmt ifmt parameters, however time period names used preference.","code":""},{"path":"/reference/labels.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label a time period — labels.time_period","text":"","code":"# S3 method for time_period labels(   object,   ...,   dfmt = \"%d/%b\",   ifmt = \"{start} — {end}\",   na.value = \"Unknown\" )"},{"path":"/reference/labels.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label a time period — labels.time_period","text":"object set decimal times time_period ... used dfmt strptime format specification format date ifmt glue spec referring start end period formatted date na.value label NA times","code":""},{"path":"/reference/labels.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label a time period — labels.time_period","text":"set character labels time","code":""},{"path":"/reference/labels.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Label a time period — labels.time_period","text":"","code":"eg = as.time_period(Sys.Date()+0:10*7, anchor=\"start\") #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S labels(eg) #> 25/Apr — 01/May #> 02/May — 08/May #> 09/May — 15/May #> 16/May — 22/May #> 23/May — 29/May #> 30/May — 05/Jun #> 06/Jun — 12/Jun #> 13/Jun — 19/Jun #> 20/Jun — 26/Jun #> 27/Jun — 03/Jul #> 04/Jul — 10/Jul labels(eg, ifmt=\"{start}\", dfmt=\"%d/%b/%y\") #> 25/Apr/24 #> 02/May/24 #> 09/May/24 #> 16/May/24 #> 23/May/24 #> 30/May/24 #> 06/Jun/24 #> 13/Jun/24 #> 20/Jun/24 #> 27/Jun/24 #> 04/Jul/24 labels(eg, ifmt=\"until {end}\", dfmt=\"%d %b %Y\") #> until 01 May 2024 #> until 08 May 2024 #> until 15 May 2024 #> until 22 May 2024 #> until 29 May 2024 #> until 05 Jun 2024 #> until 12 Jun 2024 #> until 19 Jun 2024 #> until 26 Jun 2024 #> until 03 Jul 2024 #> until 10 Jul 2024  # labels retained in constructor: eg2 = Sys.Date()+0:10*7 names(eg2) = paste0(\"week \",0:10) labels(eg2) #>  [1] \"week 0\"  \"week 1\"  \"week 2\"  \"week 3\"  \"week 4\"  \"week 5\"  \"week 6\"  #>  [8] \"week 7\"  \"week 8\"  \"week 9\"  \"week 10\" labels(as.time_period(eg2, anchor=\"start\")) #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S #>  [1] \"week 0\"  \"week 1\"  \"week 2\"  \"week 3\"  \"week 4\"  \"week 5\"  \"week 6\"  #>  [8] \"week 7\"  \"week 8\"  \"week 9\"  \"week 10\""},{"path":"/reference/logit_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"logit scale — logit_trans","title":"logit scale — logit_trans","text":"perform logit scaling right axis formatting. used directly ggplot (e.g. ggplot2::scale_y_continuous(trans = \"logit\") )","code":""},{"path":"/reference/logit_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logit scale — logit_trans","text":"","code":"logit_trans()"},{"path":"/reference/logit_trans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"logit scale — logit_trans","text":"scales object","code":""},{"path":"/reference/logit_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logit scale — logit_trans","text":"","code":"library(ggplot2) library(tibble)  tibble::tibble(pvalue = c(0.001, 0.05, 0.1), fold_change = 1:3) %>%  ggplot2::ggplot(aes(fold_change , pvalue)) +  ggplot2::geom_point() +  ggplot2::scale_y_continuous(trans = \"logit\")"},{"path":"/reference/max_date.html","id":null,"dir":"Reference","previous_headings":"","what":"The maximum of a set of dates — max_date","title":"The maximum of a set of dates — max_date","text":"max.Date returns integer -Inf set NA dates. usually inconvenient.","code":""},{"path":"/reference/max_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The maximum of a set of dates — max_date","text":"","code":"max_date(x, ...)"},{"path":"/reference/max_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The maximum of a set of dates — max_date","text":"x vector dates ... ignored","code":""},{"path":"/reference/max_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The maximum of a set of dates — max_date","text":"date. `0001-01-01`` well defined minimum.","code":""},{"path":"/reference/max_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The maximum of a set of dates — max_date","text":"","code":"max_date(NA) #> [1] \"1-01-01\""},{"path":"/reference/min_date.html","id":null,"dir":"Reference","previous_headings":"","what":"The minimum of a set of dates — min_date","title":"The minimum of a set of dates — min_date","text":"min.Date returns integer Inf set NA dates. usually inconvenient.","code":""},{"path":"/reference/min_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The minimum of a set of dates — min_date","text":"","code":"min_date(x, ...)"},{"path":"/reference/min_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The minimum of a set of dates — min_date","text":"x vector dates ... ignored","code":""},{"path":"/reference/min_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The minimum of a set of dates — min_date","text":"date. 9999-12-31 well defined minimum.","code":""},{"path":"/reference/min_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The minimum of a set of dates — min_date","text":"","code":"min_date(NA) #> [1] \"9999-12-31\""},{"path":"/reference/multinomial_nnet_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial time-series model. — multinomial_nnet_model","title":"Multinomial time-series model. — multinomial_nnet_model","text":"Takes list times, classes counts, e.g. COGUK variant like data set time, (multinomial) class (e.g. variant) count count time period. Fits quadratic B-spline time proportion data using nnet::multinom, approx one degree freedom per class per window units time series","code":""},{"path":"/reference/multinomial_nnet_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial time-series model. — multinomial_nnet_model","text":"","code":"multinomial_nnet_model(   d = i_multinomial_input,   ...,   window = 14,   frequency = \"1 day\",   predict = TRUE )"},{"path":"/reference/multinomial_nnet_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial time-series model. — multinomial_nnet_model","text":"d Multiclass count input ... used present allow proportion model used group_modify window number data points knots, smaller values result less smoothing, large value . frequency density output estimates. predict result prediction. false return model.","code":""},{"path":"/reference/multinomial_nnet_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial time-series model. — multinomial_nnet_model","text":"new dataframe time (time period), class, proportion.0.5, model object","code":""},{"path":"/reference/multinomial_nnet_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial time-series model. — multinomial_nnet_model","text":"","code":"if (FALSE) {   # not run due to long running   tmp = growthrates::england_covid %>%     dplyr::filter(date > \"2022-01-01\") %>%     growthrates::multinomial_nnet_model(window=21) %>%     dplyr::glimpse() }"},{"path":"/reference/normalise_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita — normalise_incidence","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"/reference/normalise_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"","code":"normalise_incidence(   modelled = i_timeseries,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"/reference/normalise_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"modelled Model output processing raw dataframe something like poission_locfit_model dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` mandatory groupings. default value. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"/reference/normalise_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated mandatory groupings. default value.","code":""},{"path":"/reference/normalise_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"","code":"tmp = growthrates::england_covid %>%   growthrates::poisson_locfit_model(window=21) %>%   growthrates::normalise_incidence(growthrates::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 21 #> Groups: class [19] #> $ class                       <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, … #> $ time                        <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… #> $ incidence.fit               <dbl> -17.891227, -17.395804, -16.873590, -16.33… #> $ incidence.se.fit            <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358… #> $ incidence.0.025             <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, … #> $ incidence.0.5               <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, … #> $ incidence.0.975             <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, … #> $ growth.fit                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.se.fit               <dbl> 0.05395200, 0.05584978, 0.05729669, 0.0583… #> $ growth.0.025                <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097… #> $ growth.0.5                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.0.975                <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391… #> $ population                  <int> 3077000, 3077000, 3077000, 3077000, 307700… #> $ baseline_proportion         <dbl> 0.05447011, 0.05447011, 0.05447011, 0.0544… #> $ incidence.per_capita.0.025  <dbl> 1.303228e-11, 2.086363e-11, 3.547843e-11, … #> $ incidence.per_capita.0.5    <dbl> 5.518375e-10, 9.056719e-10, 1.526742e-09, … #> $ incidence.per_capita.0.975  <dbl> 2.336695e-08, 3.931443e-08, 6.570024e-08, … #> $ incidence.per_capita.fit    <dbl> -21.317768, -20.822344, -20.300130, -19.75… #> $ incidence.per_capita.se.fit <dbl> -1.515370, -1.502694, -1.507134, -1.526504… #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, … #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, …"},{"path":"/reference/normalise_incidence.incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"/reference/normalise_incidence.incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"","code":"normalise_incidence.incidence(   modelled = i_incidence_model,   pop = i_population_data,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"/reference/normalise_incidence.incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"modelled Model output processing raw dataframe something like poission_locfit_model dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. pop population data must grouped way modelled. dataframe containing following columns: population (positive_integer) - Size population mandatory groupings. default value. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"/reference/normalise_incidence.incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated mandatory groupings. default value.","code":""},{"path":"/reference/normalise_incidence.incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"","code":"tmp = growthrates::england_covid %>%   growthrates::poisson_locfit_model(window=21) %>%   growthrates::normalise_incidence(growthrates::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 21 #> Groups: class [19] #> $ class                       <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, … #> $ time                        <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… #> $ incidence.fit               <dbl> -17.891227, -17.395804, -16.873590, -16.33… #> $ incidence.se.fit            <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358… #> $ incidence.0.025             <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, … #> $ incidence.0.5               <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, … #> $ incidence.0.975             <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, … #> $ growth.fit                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.se.fit               <dbl> 0.05395200, 0.05584978, 0.05729669, 0.0583… #> $ growth.0.025                <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097… #> $ growth.0.5                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.0.975                <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391… #> $ population                  <int> 3077000, 3077000, 3077000, 3077000, 307700… #> $ baseline_proportion         <dbl> 0.05447011, 0.05447011, 0.05447011, 0.0544… #> $ incidence.per_capita.0.025  <dbl> 1.303228e-11, 2.086363e-11, 3.547843e-11, … #> $ incidence.per_capita.0.5    <dbl> 5.518375e-10, 9.056719e-10, 1.526742e-09, … #> $ incidence.per_capita.0.975  <dbl> 2.336695e-08, 3.931443e-08, 6.570024e-08, … #> $ incidence.per_capita.fit    <dbl> -21.317768, -20.822344, -20.300130, -19.75… #> $ incidence.per_capita.se.fit <dbl> -1.515370, -1.502694, -1.507134, -1.526504… #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, … #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, …"},{"path":"/reference/normalise_incidence.proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"","code":"normalise_incidence.proportion(   modelled = i_proportion_model,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"/reference/normalise_incidence.proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"modelled Model output processing raw dataframe something like poission_locfit_model dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated mandatory groupings. default value.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"scales proportion model population unit make comparable incidence model.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"","code":"tmp = growthrates::england_covid %>%   growthrates::poisson_locfit_model(window=21) %>%   growthrates::normalise_incidence(growthrates::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 21 #> Groups: class [19] #> $ class                       <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, … #> $ time                        <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… #> $ incidence.fit               <dbl> -17.891227, -17.395804, -16.873590, -16.33… #> $ incidence.se.fit            <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358… #> $ incidence.0.025             <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, … #> $ incidence.0.5               <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, … #> $ incidence.0.975             <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, … #> $ growth.fit                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.se.fit               <dbl> 0.05395200, 0.05584978, 0.05729669, 0.0583… #> $ growth.0.025                <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097… #> $ growth.0.5                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.0.975                <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391… #> $ population                  <int> 3077000, 3077000, 3077000, 3077000, 307700… #> $ baseline_proportion         <dbl> 0.05447011, 0.05447011, 0.05447011, 0.0544… #> $ incidence.per_capita.0.025  <dbl> 1.303228e-11, 2.086363e-11, 3.547843e-11, … #> $ incidence.per_capita.0.5    <dbl> 5.518375e-10, 9.056719e-10, 1.526742e-09, … #> $ incidence.per_capita.0.975  <dbl> 2.336695e-08, 3.931443e-08, 6.570024e-08, … #> $ incidence.per_capita.fit    <dbl> -21.317768, -20.822344, -20.300130, -19.75… #> $ incidence.per_capita.se.fit <dbl> -1.515370, -1.502694, -1.507134, -1.526504… #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, … #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, …"},{"path":"/reference/normalise_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised risk ration from proportions — normalise_proportion","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"assumes case distribution proportions stratified population grouping, e.g. geography age, estimates size population time period. Normalising population proportion allows us compare groups.","code":""},{"path":"/reference/normalise_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"","code":"normalise_proportion(   modelled = i_proportion_model,   base = i_baseline_proportion_data,   ... )"},{"path":"/reference/normalise_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"modelled Model output processing raw dataframe something like proportion_locfit_model dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value. base baseline data must grouped way modelled. dataframe containing following columns: baseline_proportion (proportion) - Size population mandatory groupings. default value. ... used","code":""},{"path":"/reference/normalise_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) risk_ratio.0.025 (positive_double) - lower confidence limit excess risk ratio population group risk_ratio.0.5 (positive_double) - median estimate excess risk ratio population group risk_ratio.0.975 (positive_double) - upper confidence limit excess risk ratio population group baseline_proportion (proportion) - population baseline risk excess risk ratio based mandatory groupings. default value.","code":""},{"path":"/reference/normalise_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"","code":"tmp = growthrates::england_covid %>%   growthrates::proportion_locfit_model(window=21) %>%   growthrates::normalise_proportion(growthrates::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 17 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5… #> $ population             <dbl> 3077000, 3077000, 3077000, 3077000, 3077000, 30… #> $ baseline_proportion    <dbl> 0.05447011, 0.05447011, 0.05447011, 0.05447011,… #> $ risk_ratio.0.025       <dbl> 3.229595e-49, 1.046093e-47, 6.073711e-46, 5.491… #> $ risk_ratio.0.5         <dbl> 2.689616e-05, 3.471831e-05, 4.592981e-05, 6.190… #> $ risk_ratio.0.975       <dbl> 18.35869, 18.35869, 18.35869, 18.35869, 18.3586…  plot_growth_phase(tmp) #> Coordinate system already present. Adding new coordinate system, which will #> replace the existing one."},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"/reference/plot_growth_phase.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"Plot incidence proportion vs. growth phase diagram","code":""},{"path":"/reference/plot_growth_phase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"","code":"plot_growth_phase(   modelled = i_timestamped,   timepoints = NULL,   duration = max(dplyr::count(modelled)$n),   interval = 7,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   cis = TRUE,   ... )"},{"path":"/reference/plot_growth_phase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"modelled Either: dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. : dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value. timepoints timepoints (Date time_period vector) dates plot phase diagrams. multiple result sequence plots facets. NULL (default) last time point series duration length growth rate phase trail interval length time markers phase plot mapping ggplot2::aes() mapping cis phases marked confidence intervals? ... Arguments passed geom_events events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_growth_phase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"ggplot timeseries","code":""},{"path":"/reference/plot_growth_phase.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"","code":"# example code  tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count))  tmp_pop = growthrates::england_demographics %>%   dplyr::ungroup() %>%   dplyr::summarise(population = sum(population))  # If the incidence is normalised by population tmp2 = tmp %>%   poisson_locfit_model() %>%   normalise_incidence(tmp_pop)  timepoints = as.Date(c(\"Lockdown 1\" = \"2020-03-30\", \"Lockdown 2\" = \"2020-12-31\"))  if (FALSE) {   plot_growth_phase(tmp2, timepoints, duration=108) }"},{"path":"/reference/plot_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Growth rate timeseries diagram — plot_growth_rate","title":"Growth rate timeseries diagram — plot_growth_rate","text":"Growth rate timeseries diagram","code":""},{"path":"/reference/plot_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Growth rate timeseries diagram — plot_growth_rate","text":"","code":"plot_growth_rate(   modelled = i_timeseries,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Growth rate timeseries diagram — plot_growth_rate","text":"modelled Either: dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. : dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value. ... Arguments passed geom_events   mapping ggplot2::aes mapping. importantly setting colour something multiple incidence time series plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Growth rate timeseries diagram — plot_growth_rate","text":"ggplot timeseries","code":""},{"path":"/reference/plot_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Growth rate timeseries diagram — plot_growth_rate","text":"","code":"# example code tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count))  tmp_pop = growthrates::england_demographics %>%   dplyr::ungroup() %>%   dplyr::summarise(population = sum(population))    # If the incidence is normalised by population tmp2 = tmp %>%   poisson_locfit_model() %>%   normalise_incidence(tmp_pop)  plot_growth_rate(tmp2,colour=\"blue\")   tmp3 = growthrates::england_covid %>%   proportion_locfit_model()  # Default pdf device doesn't support unicode if (FALSE) {   plot_growth_rate(tmp3) }"},{"path":"/reference/plot_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an incidence timeseries — plot_incidence","title":"Plot an incidence timeseries — plot_incidence","text":"Plot incidence timeseries","code":""},{"path":"/reference/plot_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an incidence timeseries — plot_incidence","text":"","code":"plot_incidence(   modelled = i_incidence_model,   raw = i_incidence_data,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an incidence timeseries — plot_incidence","text":"modelled optional estimate incidence time series. modelled missing estimated raw using poisson_locfit_model. case parameters window deg may supplied control fit. dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. modelled can also output normalise_incidence case plot uses per capita rates calculated function raw raw count data dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` mandatory groupings. default value. ... Arguments passed geom_events, poisson_locfit_model window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an incidence timeseries — plot_incidence","text":"ggplot object","code":""},{"path":"/reference/plot_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an incidence timeseries — plot_incidence","text":"","code":"# example code  tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count))  tmp_pop = growthrates::england_demographics %>%   dplyr::ungroup() %>%   dplyr::summarise(population = sum(population))  # If the incidence is normalised by population tmp2 = tmp %>%   poisson_locfit_model() %>%   normalise_incidence(tmp_pop)  plot_incidence(tmp2,tmp %>% dplyr::cross_join(tmp_pop),colour=\"blue\",size=0.25)"},{"path":"/reference/plot_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a multinomial proportions mode — plot_multinomial","title":"Plot a multinomial proportions mode — plot_multinomial","text":"Plot multinomial proportions mode","code":""},{"path":"/reference/plot_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a multinomial proportions mode — plot_multinomial","text":"","code":"plot_multinomial(   modelled = i_multinomial_proportion_model,   ...,   mapping = ggplot2::aes(fill = class),   events = i_events,   normalise = FALSE )"},{"path":"/reference/plot_multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a multinomial proportions mode — plot_multinomial","text":"modelled multinomial count data dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` class (factor) - factor specifying type observation. things like variant, serotype, multinomial model. missing data points ignored. proportion.0.5 (proportion) - median estimate proportion (true scale) Must grouped : class (exactly). default value. ... Arguments passed geom_events   mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined. normalise make sure probabilities add one - can bad idea know may missing values.","code":""},{"path":"/reference/plot_multinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a multinomial proportions mode — plot_multinomial","text":"ggplot","code":""},{"path":"/reference/plot_multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a multinomial proportions mode — plot_multinomial","text":"","code":"tmp = growthrates::england_covid %>%   growthrates::proportion_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5…  plot_multinomial(tmp, normalise=TRUE)+   ggplot2::scale_fill_viridis_d()"},{"path":"/reference/plot_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a proportions timeseries — plot_proportion","title":"Plot a proportions timeseries — plot_proportion","text":"Plot proportions timeseries","code":""},{"path":"/reference/plot_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a proportions timeseries — plot_proportion","text":"","code":"plot_proportion(   modelled = i_proportion_model,   raw = i_proportion_data,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a proportions timeseries — plot_proportion","text":"modelled Proportion model estimates dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value. raw Raw count data dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` mandatory groupings. default value. ... Arguments passed geom_events, proportion_locfit_model window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a proportions timeseries — plot_proportion","text":"ggplot object","code":""},{"path":"/reference/plot_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a proportions timeseries — plot_proportion","text":"","code":"tmp = growthrates::england_covid %>%   growthrates::proportion_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5…  plot_proportion(tmp)+   ggplot2::scale_fill_viridis_d(aesthetics = c(\"fill\",\"colour\"))"},{"path":"/reference/plot_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number timeseries diagram — plot_rt","title":"Reproduction number timeseries diagram — plot_rt","text":"Reproduction number timeseries diagram","code":""},{"path":"/reference/plot_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number timeseries diagram — plot_rt","text":"","code":"plot_rt(   modelled = i_reproduction_number,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_rt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number timeseries diagram — plot_rt","text":"modelled modelled Rt estimate dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value. ... Arguments passed geom_events   mapping ggplot2::aes mapping. importantly setting colour something multiple incidence time series plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_rt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number timeseries diagram — plot_rt","text":"ggplot timeseries","code":""},{"path":"/reference/plot_rt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number timeseries diagram — plot_rt","text":"","code":"# example code tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count)) if (FALSE) {    tmp2 = tmp %>%     poisson_locfit_model() %>%     rt_from_growth_rate()    # comparing RT from growth rates with England consensus Rt:   plot_rt(tmp2,colour=\"blue\")+     geom_errorbar(data=england_consensus_rt, mapping=aes(x=date-21,ymin=low,ymax=high),colour=\"red\")  }"},{"path":"/reference/poisson_glm_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson time-series model. — poisson_glm_model","title":"Poisson time-series model. — poisson_glm_model","text":"uses generalised linear model fit quasi-poisson model time varying rate natural cubic spline approx one degree freedom per window units time series.","code":""},{"path":"/reference/poisson_glm_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson time-series model. — poisson_glm_model","text":"","code":"poisson_glm_model(d = i_incidence_input, ..., window = 14, frequency = \"1 day\")"},{"path":"/reference/poisson_glm_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson time-series model. — poisson_glm_model","text":"d Count model input dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\")","code":""},{"path":"/reference/poisson_glm_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson time-series model. — poisson_glm_model","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value.","code":""},{"path":"/reference/poisson_glm_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson time-series model. — poisson_glm_model","text":"","code":"tmp = growthrates::england_covid %>%  growthrates::poisson_glm_model(window=21) %>%  dplyr::glimpse() #> Rows: 26,790 #> Columns: 7 #> Groups: class [19] #> $ class            <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_0… #> $ time             <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14… #> $ incidence.fit    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.se.fit <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.0.025  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.0.5    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.0.975  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"},{"path":"/reference/poisson_locfit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson time-series model. — poisson_locfit_model","title":"Poisson time-series model. — poisson_locfit_model","text":"Takes list times counts fits quasi-poisson model fitted log link function count data using local regression using package locfit.","code":""},{"path":"/reference/poisson_locfit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson time-series model. — poisson_locfit_model","text":"","code":"poisson_locfit_model(   d = i_incidence_input,   ...,   window = 14,   deg = 1,   frequency = \"1 day\",   predict = TRUE )"},{"path":"/reference/poisson_locfit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson time-series model. — poisson_locfit_model","text":"d input data dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") predict result prediction dataframe. false return locfit models (advanced). - (defaults TRUE)","code":""},{"path":"/reference/poisson_locfit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson time-series model. — poisson_locfit_model","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value.","code":""},{"path":"/reference/poisson_locfit_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson time-series model. — poisson_locfit_model","text":"results incidence rate estimate plus absolute exponential growth rate estimate based time unit input data (e.g. daily data rate cases per day growth rate daily).","code":""},{"path":"/reference/poisson_locfit_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson time-series model. — poisson_locfit_model","text":"","code":"growthrates::england_covid %>%   growthrates::poisson_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class            <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_0… #> $ time             <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14… #> $ incidence.fit    <dbl> -17.891227, -17.395804, -16.873590, -16.331042, -15.7… #> $ incidence.se.fit <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358, 1.8681012… #> $ incidence.0.025  <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, 1.950766e-0… #> $ incidence.0.5    <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, 8.081996e-0… #> $ incidence.0.975  <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, 3.348359e-0… #> $ growth.fit       <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723010… #> $ growth.se.fit    <dbl> 0.05395200, 0.05584978, 0.05729669, 0.05835042, 0.059… #> $ growth.0.025     <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097, 0.3565117… #> $ growth.0.5       <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723010… #> $ growth.0.975     <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391, 0.5880903…"},{"path":"/reference/proportion_glm_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Binomial time-series model. — proportion_glm_model","title":"Binomial time-series model. — proportion_glm_model","text":"uses generalised linear model fit quasi-binomial model time varying rate natural cubic spline approx one degree freedom per window units time series.","code":""},{"path":"/reference/proportion_glm_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binomial time-series model. — proportion_glm_model","text":"","code":"proportion_glm_model(   d = i_proportion_input,   ...,   window = 14,   frequency = \"1 day\" )"},{"path":"/reference/proportion_glm_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binomial time-series model. — proportion_glm_model","text":"d Proportion model input dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\")","code":""},{"path":"/reference/proportion_glm_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binomial time-series model. — proportion_glm_model","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value.","code":""},{"path":"/reference/proportion_glm_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binomial time-series model. — proportion_glm_model","text":"","code":"# TODO: find out cause of the warnings # \"observations with zero weight not used for calculating dispersion\" suppressWarnings(   growthrates::england_covid %>%    growthrates::proportion_glm_model(window=21) %>%    dplyr::glimpse() ) #> Rows: 26,790 #> Columns: 7 #> Groups: class [19] #> $ class             <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_… #> $ time              <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1… #> $ proportion.fit    <dbl> -8.889667, -8.842042, -8.794113, -8.745576, -8.69612… #> $ proportion.se.fit <dbl> 51.296631, 48.776606, 46.264194, 43.765615, 41.28710… #> $ proportion.0.025  <dbl> 2.220446e-16, 2.220446e-16, 2.220446e-16, 2.220446e-… #> $ proportion.0.5    <dbl> 0.0001377866, 0.0001445064, 0.0001516000, 0.00015913… #> $ proportion.0.975  <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.000000…"},{"path":"/reference/proportion_locfit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"takes list times, counts denominator fits quasi-binomial model using logit link function proportion data using local regression using package locfit.","code":""},{"path":"/reference/proportion_locfit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"","code":"proportion_locfit_model(   d = i_proportion_input,   ...,   window = 14,   deg = 1,   frequency = \"1 day\",   predict = TRUE )"},{"path":"/reference/proportion_locfit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"d input dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") predict result prediction dataframe. false return locfit models (advanced). - (defaults TRUE)","code":""},{"path":"/reference/proportion_locfit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value.","code":""},{"path":"/reference/proportion_locfit_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"expects d contain one combination : time count denom columns - e.g. tests conducted. results one versus others comparison binomial proportion estimate plus relative growth rate estimate specifying much quicker growing compared growth denominator. denominator maybe sum subgroups denom = sum(count), e.g. situation multiple variants disease circulating. case relative growth subgroup compared overall. can make one-versus-others comparison making denominator exclude current item (e.g. denom = sum(count)-count). denominator can also used express size population tested. gives us relative growth rate different essence previous may better estimate true growth rate situation testing effort variable, capacity saturated.","code":""},{"path":"/reference/proportion_locfit_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"","code":"growthrates::england_covid %>%  growthrates::proportion_locfit_model(window=21) %>%  dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5…"},{"path":"/reference/reband_discrete.html","id":null,"dir":"Reference","previous_headings":"","what":"Reband any discrete distribution — reband_discrete","title":"Reband any discrete distribution — reband_discrete","text":"e.g. age banded population, discrete probability distribution e.g. serial interval distribution.","code":""},{"path":"/reference/reband_discrete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reband any discrete distribution — reband_discrete","text":"","code":"reband_discrete(   x,   y,   xout,   xlim = c(0, NA),   ytotal = c(0, sum(y)),   digits = 0,   labelling = c(\"positive_integer\", \"inclusive\", \"exclusive\"),   sep = \"-\" )"},{"path":"/reference/reband_discrete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reband any discrete distribution — reband_discrete","text":"x set upper limits bands, e.g. age: 0-14;15-64;65-79;80+ 15,65,80,NA y set quantities band e.g. population figures xout set new upper limits xlim Upper lower limits x. last band e.g 80+ input want know 85+ band output kind maximum upper limit needed interpolate . ytotal upper lower limits y. interpolation values fall outside x max limits y given . digits xout value continuous many significant figures put labels labelling xout values interpretable inclusive upper limit, exclusive upper limit, upper limit `positive_integer`` quantity sep seperator names e.g. 18-24 18 24","code":""},{"path":"/reference/reband_discrete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reband any discrete distribution — reband_discrete","text":"rebanded set discrete values, guaranteed sum y","code":""},{"path":"/reference/reband_discrete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reband any discrete distribution — reband_discrete","text":"","code":"ul = stringr::str_extract(england_demographics$class, \"_([0-9]+)\",group = 1) %>%   as.numeric()  tmp = reband_discrete(   ul, england_demographics$population,   c(5,10,15,40,80), xlim=c(0,120))  tmp #>      0-4      5-9    10-14    15-39    40-79      80+  #>  3745688  3361511  3384582 18173104 25360084  2464731   sum(tmp) #> [1] 56489700 sum(england_demographics$population) #> [1] 56489700"},{"path":"/reference/rt_epiestim.html","id":null,"dir":"Reference","previous_headings":"","what":"EpiEstim reproduction number — rt_epiestim","title":"EpiEstim reproduction number — rt_epiestim","text":"Calculate reproduction number estimate incidence data using EpiEstim library empirical generation time distribution. uses resampling transmit uncertainty generation time estimates. quite slow time series depending number bootstraps samples infectivity profile.","code":""},{"path":"/reference/rt_epiestim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EpiEstim reproduction number — rt_epiestim","text":"","code":"rt_epiestim(   df = i_incidence_input,   ip = i_infectivity_profile,   bootstraps = 2000,   window = 14,   mean_prior = 1,   std_prior = 2,   ... )"},{"path":"/reference/rt_epiestim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EpiEstim reproduction number — rt_epiestim","text":"df Count data. Extra groups allowed. dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ip infectivity profile dataframe containing following columns: boot (anything) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined. bootstraps number bootstraps take calculate point. window width epiestim window mean_prior prior $R_t$ estimate. sample size low $R_t$ estimate revert prior. EpiEstim default high number allow detection insufficient data tends create anomalies early part infection timeseries. possible value $R_0$ fact also poor choice value $R_t$ case numbers drop low value. std_prior prior $R_t$ SD. ... used","code":""},{"path":"/reference/rt_epiestim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EpiEstim reproduction number — rt_epiestim","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_epiestim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EpiEstim reproduction number — rt_epiestim","text":"calculate reproduction number group input dataframe.","code":""},{"path":"/reference/rt_epiestim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EpiEstim reproduction number — rt_epiestim","text":"","code":"tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count))  if (FALSE) {   # not run due to long running   tmp2 = tmp %>% rt_epiestim() }"},{"path":"/reference/rt_from_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"Calculate reproduction number estimate growth rate using Wallinga 2007 estimation using empirical generation time distribution. uses resampling transmit uncertainty growth rate estimates","code":""},{"path":"/reference/rt_from_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"","code":"rt_from_growth_rate(   df = i_growth_rate,   ip = i_infectivity_profile,   bootstraps = 2000 )"},{"path":"/reference/rt_from_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"df Growth rate estimates dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. ip Infectivity profile dataframe containing following columns: boot (anything) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined. bootstraps number bootstraps take calculate point.","code":""},{"path":"/reference/rt_from_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_from_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"","code":"tmp = growthrates::england_covid %>%   time_aggregate(count=sum(count))   if (FALSE) {   # not run   tmp2 = tmp %>%     poisson_locfit_model() %>%     rt_from_growth_rate() }"},{"path":"/reference/rt_from_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number from modelled incidence — rt_from_incidence","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"Calculate reproduction number estimate growth rate using methods described vignette \"Estimating reproduction number modelled incidence\" using empirical generation time distribution.","code":""},{"path":"/reference/rt_from_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"","code":"rt_from_incidence(df = i_incidence_model, ip = i_infectivity_profile)"},{"path":"/reference/rt_from_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"df Count data dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. ip Infectivity profile dataframe containing following columns: boot (anything) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined.","code":""},{"path":"/reference/rt_from_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"dataframe containing following columns: time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_from_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"","code":"df = growthrates::england_covid %>%   time_aggregate(count=sum(count)) %>%     poisson_locfit_model()   if (FALSE) {   # not run   tmp2 = df %>% rt_from_incidence() }"},{"path":"/reference/scale_y_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A log1p y scale — scale_y_log1p","title":"A log1p y scale — scale_y_log1p","text":"log1p y scale","code":""},{"path":"/reference/scale_y_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A log1p y scale — scale_y_log1p","text":"","code":"scale_y_log1p(..., n = 5, base = 10, dp = 0)"},{"path":"/reference/scale_y_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A log1p y scale — scale_y_log1p","text":"... arguments passed scale_(x|y)_continuous() n number major breaks base base logarithm dp decimal points","code":""},{"path":"/reference/scale_y_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A log1p y scale — scale_y_log1p","text":"ggplot scale","code":""},{"path":"/reference/scale_y_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"A logit y scale — scale_y_logit","title":"A logit y scale — scale_y_logit","text":"logit y scale","code":""},{"path":"/reference/scale_y_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A logit y scale — scale_y_logit","text":"","code":"scale_y_logit(...)"},{"path":"/reference/scale_y_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A logit y scale — scale_y_logit","text":"... arguments passed scale_(x|y)_continuous()","code":""},{"path":"/reference/scale_y_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A logit y scale — scale_y_logit","text":"ggplot scale","code":""},{"path":"/reference/time_aggregate.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate time series data preserving the time series — time_aggregate","title":"Aggregate time series data preserving the time series — time_aggregate","text":"Aggregate time series data preserving time series","code":""},{"path":"/reference/time_aggregate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate time series data preserving the time series — time_aggregate","text":"","code":"time_aggregate(   df = i_timestamped,   ...,   .groups = NULL,   .cols = NULL,   .fns = NULL )"},{"path":"/reference/time_aggregate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate time series data preserving the time series — time_aggregate","text":"df optionally grouped time series. Grouping include time column. grouping works differently dplyr::summarise last level non-time groups lost operation, subgroup wish aggregate included grouping. ... set dplyr::summarise statements, additional parameters .fns .groups per dplyr::summarise .cols Optional tidyselect column specification dplyr::across. .fns given .cols parameter specified columns summarise automatically identified. Date columns dropped. want .cols ... must given .fns Optional set function specifications per dplyr::across","code":""},{"path":"/reference/time_aggregate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate time series data preserving the time series — time_aggregate","text":"summarised time series preserving time column, grouping structure involving one fewer levels input","code":""},{"path":"/reference/time_aggregate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate time series data preserving the time series — time_aggregate","text":"","code":"growthrates::england_covid %>%   time_aggregate(count = sum(count), denom = sum(denom)) %>%   dplyr::glimpse() #> Rows: 1,410 #> Columns: 3 #> $ time  <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1… #> $ count <dbl> 1, 0, 0, 1, 18, 0, 1, 0, 0, 3, 1, 1, 3, 1, 1, 0, 0, 0, 1, 0, 0, … #> $ denom <dbl> 19, 0, 0, 19, 342, 0, 19, 0, 0, 57, 19, 19, 57, 19, 19, 0, 0, 0,…  growthrates::england_covid %>%   time_aggregate(.fns=mean) %>%   dplyr::glimpse() #> Rows: 1,410 #> Columns: 3 #> $ time  <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1… #> $ count <dbl> 0.05263158, 0.00000000, 0.00000000, 0.05263158, 0.94736842, 0.00… #> $ denom <dbl> 1, 0, 0, 1, 18, 0, 1, 0, 0, 3, 1, 1, 3, 1, 1, 0, 0, 0, 1, 0, 0, …"},{"path":"/reference/time_summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise data from a line list to a time-series of counts. — time_summarise","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"principally designed take record single events produce summary time-series count events group, class date. default behaviour guess cadence input data summarise event line list (set ) regular time-series counts use incidence growth rate estimates.","code":""},{"path":"/reference/time_summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"","code":"time_summarise(   df = i_dated,   unit,   anchor = \"start\",   rectangular = FALSE,   ...,   .fill = list(count = 0) )"},{"path":"/reference/time_summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"df line list data want summarise, optionally grouped. grouped group treated independently. remaining columns must contain date column may contain class column. count column present counts summed, otherwise individual row counted single event (linelist) unit period e.g. \"1 week\" anchor one date, \"start\" \"end\" weekday name e.g. \"mon\" always one start time periods cutting rectangular resulting time series length groups. case can sure data complete subgroups, otherwise missing data treated zero counts. important leading trailing missing data one subgroup can due reporting delay subgroup, case rectangular time series erroneously fill zero counts missing data. ... spec dplyr::summary(...) - optional, provided count = dplyr::n() count = sum(count) performed. .fill list similar tidyr::complete values fill variables ","code":""},{"path":"/reference/time_summarise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"output depends whether input grouped class column. detailed output : dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period mandatory groupings. default value. minimal output input plain list dated events: dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (.time_period + group_unique) - (usually complete) set singular observations per unit time time_period mandatory groupings. default value.","code":""},{"path":"/reference/time_summarise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"data given class column time series interpreted denominator, consisting different classes within time period. may subtypes (e.g. variants, serotypes) markers test positivity. either case resulting time series counts classes denominators combination. flexibility kinds summarisation raw data count based (e.g. means continuous variables) case slider package usually going better, time summarise look non overlapping time periods fixed lengths. another use case existing  timeseries particular frequency aggregated another less frequent basis (e.g. moving daily timeseries weekly one). case input contain count column. mode checks made frequent events present summarisation result may include different numbers input periods (e.g. going weeks months may 4 5 weeks month)","code":""},{"path":"/reference/time_to_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a set of timepoints to dates — time_to_date","title":"Convert a set of timepoints to dates — time_to_date","text":"Convert set timepoints dates","code":""},{"path":"/reference/time_to_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a set of timepoints to dates — time_to_date","text":"","code":"time_to_date(   timepoints,   unit = attr(timepoints, \"unit\"),   start_date = attr(timepoints, \"start_date\") )"},{"path":"/reference/time_to_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a set of timepoints to dates — time_to_date","text":"timepoints set numeric time points unit period / unit time points, extracted timepoints possible start_date zero day time series, extracted timepoints possible","code":""},{"path":"/reference/time_to_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a set of timepoints to dates — time_to_date","text":"vector dates","code":""},{"path":"/reference/time_to_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a set of timepoints to dates — time_to_date","text":"","code":"times = date_to_time(as.Date(\"2019-12-29\")+0:100, \"1 week\") dates = time_to_date(times)"},{"path":"/reference/wallinga_lipsitch.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"Calculate reproduction number growth rate estimate infectivity profile","code":""},{"path":"/reference/wallinga_lipsitch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"","code":"wallinga_lipsitch(r, y, a = 1:length(y))"},{"path":"/reference/wallinga_lipsitch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"r growth rate (may vector) y empirical infectivity profile probability vector, starting P(0<t,[1]) end time estimate (defaults single days).","code":""},{"path":"/reference/wallinga_lipsitch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"reproduction number estimate based r","code":""},{"path":"/reference/wallinga_lipsitch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"","code":"wallinga_lipsitch(r=seq(-0.1,0.1,length.out=9), y=dgamma(1:50, 5,2)) #> [1] 0.8140287 0.8581458 0.9038343 0.9511131 1.0000000 1.0505120 1.1026647 #> [8] 1.1564727 1.2119494"}]
